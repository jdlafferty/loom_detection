%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ELIFE ARTICLE TEMPLATE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PREAMBLE
\documentclass[pdftex,9pt,lineno]{elife}
% Use the onehalfspacing option for 1.5 line spacing
% Use the doublespacing option for 2.0 line spacing
% Please note that these options may affect formatting.
% Additionally, the use of the \newcommand function should be limited.

\usepackage{lipsum} % Required to insert dummy text
\usepackage[version=4]{mhchem}
\usepackage{siunitx}
\DeclareSIUnit\Molar{M}

\usepackage{amsmath}
\newcommand{\norm}[1]{\Vert {#1} \Vert}
\newcommand{\inprod}[2]{\ensuremath{\langle #1 , \, #2 \rangle}}
\newcommand{\mc}{\mathcal}
\newcommand{\mb}{\mathbb}
\newcommand{\emp}{\emptyset}
\newcommand{\sigmoid}{\text{sigmoid}}
\newcommand{\relu}{\text{\small\sc ReLU}}
\def\htheta{{\hat\theta}}
\def\k{{k}}
\def\d{{d}}
\def\reals{{\mathbb R}}
\def\({\left(}
\def\){\right)}
\def\[{\left[}
\def\]{\right]}
\def\bone{{\mathbf 1}}
\let\hat\widehat

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\trace}{tr}
\DeclareMathOperator*{\Var}{Var}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{A shallow neural network trained to detect collisions recovers features of visual loom-selective neurons}
% A shallow artificial neural network recovers properties of visual loom-selective neurons
% A simple network trained to detect collisions recovers features of visual loom-selective neurons
% Collision-detection inference, visual loom-selective neurons, shallow neural network (in abstract), simple neural network, collisions, impending collisions, Drosophila (in abstract), predicts, recovers, reproduces, *features, structure,

\author[1,2]{Baohua Zhou}
\author[2\authfn{1}]{Zifan Li}
\author[2\authfn{2}]{Sunnie S. Y. Kim}
\author[2*]{John Lafferty}
\author[1,3,4,5*]{Damon A. Clark}

\affil[1]{Department of Molecular, Cellular and Developmental Biology, Yale University, New Haven, United States}
\affil[2]{Department of Statistics and Data Science, Yale University, New Haven, United States}
\affil[3]{Interdepartmental Neuroscience Program, Yale University, New Haven, United States}
\affil[4]{Department of Physics, Yale University, New Haven, United States}
\affil[5]{Department of Neuroscience, Yale University, New Haven, United States}

\corr{damon.clark@yale.edu}{DAC}
\corr{john.lafferty@yale.edu}{JDL}

% \contrib[\authfn{1}]{These authors contributed equally to this work}
% \contrib[\authfn{2}]{These authors also contributed equally to this work}

\presentadd[\authfn{1}]{Facebook, Menlo Park, United States}
\presentadd[\authfn{2}]{Department of Computer Science, Princeton University, New Jersey, United States}
% \presentadd[\authfn{5}]{eLife Sciences editorial Office, eLife Sciences, Cambridge, United Kingdom}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE START
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
% Please provide an abstract of no more than 150 words. Your abstract should explain the main contributions of your article, and should not contain any material that is not included in the main text.
% Animals have evolved sophisticated visual circuits to detect looming objects. Studies of the visual system of \textit{Drosophila} have revealed that looming stimuli are selectively encoded by a suite of neurons, including LPLC2 neurons. In LPLC2 neurons, the dendrites are arranged in a distinctive anatomical structure and receive excitatory and inhibitory inputs that cause them to respond selectively to the radial expansion of the edges of a looming object. Our study aims to understand how the computations in LPLC2 neurons are related to the inference problem that the neuron appears to be solving: whether an object is looming towards teh fly. To do this, we trained anatomically-constrained shallow neural networks to detect whether or not a visual signal is an object on a collision course. We used these trained inference models ask how known properties of the biological neural circuits relate to the features of the artificial neural network trained on synthetic visual stimuli. We trained a single unit of our model on a set of diverse artificial visual stimuli to detect whether moving objects were on a collision course with the detector location. Surprisingly, the model arrived at two distinct solutions to this detection problem: one with dendritic weighting that mirrored LPLC2 and the other selective for inward-directed motion. We analyzed how each of these two solutions work to detect looming events. When we increased the number of units in the population, the performance of the model improved, and weighting similar to LPLC2 became more favored. When many units tiled visual space, the trained models also exhbited many of the response properties measured in LPLC2. Our findings suggests that LPLC2 can be understood as solving an inference problem, and that signals from the entire population of LPLC2 neurons are critical for understanding how LPLC2 reliably encodes looming stimuli.

% In the visual system of \textit{Drosophila}, looming stimuli are selectively encoded by a suite of neurons, including LPLC2 neurons. The dendrites of the LPLC2 neurons are arranged in a distinctive structure that causes them to respond selectively to the outward expansion of the edges of a looming object. To understand the structure of this looming computation, we trained an anatomically-constrained shallow neural network to detect whether or not a visual signal corresponds to an object on a collision course. Surprisingly, the model arrived at two distinct solutions: one with dendritic weighting mirroring LPLC2 and the other selective for inward-directed motion. The LPLC2-mirroring solutions were favored when a population of model units was trained on the task. The trained models reproduced LPLC2 neuronâ€™s response patterns for a large range of stimuli, as well as canonical tuning measured in loom sensitive neurons, even though they were not trained on any neural data. These models show that LPLC2's properties and tuning are predicted by optimizing a neural network to detect looming events.

Animals have evolved sophisticated visual circuits to solve a vital inference problem: detecting whether or not a visual signal corresponds to an object on a collision course. Such events are detected by specific circuits sensitive to visual looming, or objects increasing in size. Various computational models have been developed for these circuits, but how the collision-detection inference problem itself shapes the computational structures of these circuits is unknown. Here, inspired by the distinctive structures of LPLC2 neurons in the visual system of \textit{Drosophila}, we build an anatomically-constrained shallow neural network model and train it to identify visual signals that correspond to impending collisions. Surprisingly, the optimization arrives at two distinct, opposite solutions, only one of which matches the actual dendritic weighting of LPLC2 neurons. The LPLC2-like solutions are favored when a large population of model units is trained on the task, rather than training units in isolation. The trained model reproduces experimentally observed LPLC2 neuron response patterns for many stimuli, and reproduces canonical tuning of loom sensitive neurons, even though the models are never trained on any neural data. These results show that LPLC2 neuron properties and tunings are predicted by optimizing an anatomically-constrained neural network to detect impending collisions.

\end{abstract}


\section{Introduction}

\begin{figure}
\includegraphics[width=\linewidth]{figures/anatomy_paper.pdf}
\caption{Sketches of the anatomy of LPLC2 neurons \citep{klapoetke2017ultra}. (A) An LPLC2 neuron has dendrites in lobula and the four layers of the lobula plate (LP): LP1, LP2, LP3 and LP4. (B) Schematic of the four branches of the LPLC2 dendrites in the four layers of the LP. The arrows indicate the preferred direction of motion sensing neurons with axons in each LP layer \citep{maisak2013directional}. (C) The outward dendritic structure of an LPLC2 neuron is selective for the outwardly expanding edges of a looming object (black circle). (D) The axons of a population of more than 200 LPLC2 neurons converge to the GF, a descending neuron, to contribute to signaling for escaping behaviors \citep{ache2019neural}}
\label{fig:anatomy}
\end{figure}

For animals living in dynamic visual environments, it is important to detect the approach of predators or other dangerous objects. Many species, from insects to humans, rely on a range of visual cues to identify approaching, or looming, objects \citep{regan1978looming,sun1998computation,gabbiani1999computation,card2008visually,munch2009approach,temizer2015visual}. Among other cues, looming objects create characteristic visual flow fields. When an object is on a ballistic collision course with an animal, its edges will appear to the observer to expand radially outward, gradually occupying a larger and larger portion of the visual field. An object heading towards the animal, but which will not collide with it, also expands to occupy an increasing portion of the visual field, but its edges do not expand radially outwards with respect to the observer. Instead, they expand with respect to the object's center so that opposite edges are perceived to be moving in the same direction (\FIG{stimuliFlow}). A collision detector must distinguish between these two cases, while also avoiding predicting collisions in response to a myriad of other visual flow fields created by the animal's own motion. Thus, loom detection can be framed as a visual inference problem.

Many sighted animals solve this inference problem with high precision, thanks to robust loom-selective neural circuits evolved over hundreds of millions of years. The neuronal mechanisms for response to looming stimuli have been studied in a wide range of vertebrates, from cats and mice to zebrafish, as well as in humans
\citep{king1992use,hervais2015looming,ball1971infant,liu2011neuronal,salay2018midline,liu2011neuronal,shang2015parvalbumin,wu2005tectal,temizer2015visual,dunn2016neural,bhattacharyya2017visual}.
In invertebrates, detailed anatomical, neurophysiological, behavioral and modeling studies have investigated loom detection, especially for locusts and flies \citep{oliva2014computation,sato2014role,santer2005gliding,rind1996neural,card2008visually,de2012loom,muijres2014flies,klapoetke2017ultra,von2017feature,ache2019neural}.
An influential mathematical model of loom detection was derived by studying the responses of the giant descending neurons of locusts, which established a relationship between the timing of the neurons' peak responses and an angular size threshold for the looming object \citep{gabbiani1999computation}. Similar models have been applied to analyze neuronal responses to looming signals in flies, where genetic tools make it possible to precisely dissect neural circuits, revealing various neuron types that are sensitive to looming signals \citep{von2017feature,ache2019neural,morimoto2020spatial}.  However, these computational studies did not directly investigate the relationship between the structure of the loom-sensitive neural circuits and the inference problem they appear to solve. Here, we asked whether we can achieve the properties associated with neural loom detection simply by optimizing shallow neural networks for collision detection.

The starting point for our computational model of loom detection is the known neuroanatomy of the visual system of the fly. In particular, the loom-sensitive neuron LPLC2 (lobula plate/lobula columnar, type 2) \citep{wu2016visual} has been studied in detail. These neurons tile visual space, sending their axons to a descending neuron called the giant fiber (GF), which triggers  the fly's jumping and take-off behaviors \citep{tanouye1980motor,card2008visually,von2017feature,ache2019neural}. Each LPLC2 neuron has four dendritic branches that receive inputs from the four layers of the lobula plate (LP) (\FIG{anatomy}A) \citep{maisak2013directional,klapoetke2017ultra}. The retinotopic LP layers host the axon terminals of motion detection neurons, and each layer uniquely receives motion information in one of the four cardinal directions \citep{maisak2013directional}. Moreover, the physical extensions of the LPLC2 dendrites align with the preferred motion directions in the corresponding LP layers (\FIG{anatomy}B) \citep{klapoetke2017ultra}. These dendrites form an outward radial structure, which matches the moving edges of a looming object that expands in the visual field (\FIG{anatomy}C). Common stimuli such as the wide-field motion generated by movement of the insect only match part of the radial structure, and strong inhibition for inward-directed motion suppresses responses to such stimuli. Thus, the structure of the LPLC2 dendrites favors responses to objects with edges moving radially outwards, corresponding to motion toward center of the receptive field.

The focus of this paper is to investigate how loom detection in LPLC2 can be seen as the solution to a computational inference problem. Can the structure of the LPLC2 neurons be explained in terms of optimization---carried out during the course of evolution---for the task of predicting which trajectories will result in collisions?
How does coordination among the population of more than 200 LPLC2 neurons tiling a fly's visual system effect this optimization?  To answer these questions, we built a simple anatomically-constrained neural network model, which receives motion signals in the four cardinal directions. We trained the model to detect visual objects on a collision course with the observer using artificial stimuli. Surprisingly, optimization finds two distinct types of solutions, with one resembling the LPLC2 neurons and another having a very different configuration. We analyze how each of these solutions detects looming events and where they show distinct individual and population behaviors.
When the number of units tiling visual space is increased, the solutions that resemble the actual LPLC2 neurons perform better and become favored. When tested on visual stimuli not in the training data, the optimized solutions exhibit response curves that are similar to those of actual LPLC2 neurons as measured by \cite{klapoetke2017ultra}. Importantly, the optimized model reproduces the canonical linear relationship between the peak time relative to collision and the size-to-speed ratio. It also shows characteristics of an angular size encoder, which is consistent with many loom detectors, is surprising because LPLC2 receives strong motion signals \citep{gabbiani1999computation,von2017feature,ache2019neural}. Our results show that optimizing a neural network to detect looming events gives rise to the properties and tuning of LPLC2 neurons.

\section{Results}

\subsection{A set of artificial visual stimuli is designed for training models}

Our goal is to compare computational models trained to perform loom-detection with the biological computations in LPLC2. We first created a set of stimuli to act as training data for the inference task. We considered the following four types of motion stimuli: loom-and-hit (abbreviated as hit), loom-and-miss (miss), retreat, and rotation (\FIG{stimuliTraj}). The hit stimuli consist of a sphere that moves ballistically towards the origin on a collision course. The miss stimuli consist of a sphere that moves ballistically towards the origin but misses it. The retreat stimuli consist of a sphere moving ballistically away from the origin. The rotation stimuli consist of objects rotating about an axis going through the origin. All stimuli were designed to be isotropic; the first three stimuli could have any orientation in space, while the rotation could be about any axis. All trajectories were simulated in the frame of reference of the fly at the origin, with distances measured with respect to the origin. For simplicity, the fly is assumed to be a point particle with no volume (Red dots in \FIG{stimuliTraj} and the apexes of the cones in \FIG{stimuliFlow}). For hit, miss, and retreat stimuli, the spherical object has unit radius, and for the case of rotation, there were 100 objects of various radii scattered isotropically around the fly (\FIG{stimuliFlow}).

\begin{figure}
\includegraphics[width=\linewidth]{figures/stimuli_1_paper.pdf}
\caption{Four types of synthetic stimuli (\nameref{sec:methods}). (A) Orange lines represent trajectories of the stimuli. The black dots represent the starting points of the trajectories. For hit, miss, and retreat cases, multiple trajectories are shown. For rotation, only one trajectory is shown. (B) Distances of the objects to the fly eye as a function of time step. Among misses, only the approaching portion of the trajectory was used.}
\label{fig:stimuliTraj}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
% \figsupp[Shorter caption for main text.]{This is a supplementary figure's full caption, which will be used at the end of the manuscript.}{\includegraphics[width=6cm]{frog}}\label{figsupp:sf1}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{figures/stimuli_2_paper.pdf}
\caption{Snapshots of optical flows and flow fields calculated by a Hassenstein Reichardt correlator (HRC) model (\nameref{sec:methods}) for the 4 types of stimuli (\FIG{stimuliTraj}). First row: 3d rendering of the spherical objects and the LPLC2 receptive field (represented by a cone) at a specific time in the trajectory. The orange arrows indicate the motion direction of each object. Second row: 2d projections of the objects (black shading) within the LPLC2 receptive field (the grey circles). Third row: the thin black arrows indicate flow fields generated by the edges of the moving objects. Forth to seventh rows: decomposition of the flow fields in the four cardinal directions with respect to the LPLC2 neuron under consideration: downward, upward, rightward, and leftward, as indicated by the thick black arrows. These act as models of the motion signal fields in each layer of the lobula plate.}
\label{fig:stimuliFlow}
\figsupp[Tuning curve of HRC motion estimator and distributions of HRC outputs.]{(A) Tuning curve (red) of the HRC motion estimator. Grey shade indicates the velocity range used in simulations (\nameref{sec:methods}). (B) The distributions of all the HRC outputs for different types of stimuli. Note that the hit distribution is entirely hidden behind the retreat curve}{\includegraphics[width=\linewidth]{sup_figures/stimuli_2_sup_paper.pdf}}\label{figsupp:sf1}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
\end{figure}


\subsection{An anatomically-constrained mathematical model}

We designed and trained a simple, anatomically-constrained neural network (\FIG{model} to infer whether or not a moving object will collide with the fly. The features of this network are designed to mirror anatomical features of the fly's LPLC2 neurons (\FIG{anatomy}). Model units receive input from a 60 degree diameter cone of visual space, represented by white cones and grey circles in \FIG{stimuliFlow}, mirroring the receptive field size that has been measured for LPLC2 \citep{klapoetke2017ultra}. The four stimulus sets were projected into this receptive field for training and evaluating the model. The inputs to the model are local directional signals computed in the four cardinal directions at each point of visual space: downward , upward, rightward, and leftward (\FIG{stimuliFlow}). These represent the motion signals from T4 and T5 neurons in the four layers of the lobula plate \citep{maisak2013directional}. They are computed as the non-negative components of a Hassenstein-Reichardt correlator model \citep{hassenstein1956systemtheoretische} in both horizontal and vertical directions, which acts on the intensities of the projected stimuli (see Methods). The motion signals are computed with a spacing of 5 degrees, roughly matching the spacing of the ommatidia and processing columns in the fly eye \citep{stavenga2003angular}.

Each model unit can weight the motion signals from the four layers using linear spatial filters. There are two sets of non-negative filters, the excitatory filters and the inhibitory filters; these are shown in red and blue, respectively (\FIG{model}A). Each set of filters has four components, or branches, integrating motion signals from the four cardinal directions, respectively. These spatial filters represent excitatory inputs to LPLC2 directly from T4 and T5 in the LP, and inhibitory inputs  mediated by local interneurons \citep{klapoetke2017ultra,mauss2015neural}. All eight filters act on the 60 degree receptive field of an unit. A 90-degree rotational symmetry is imposed on the filters, so that the filters in each layer are identical. Moreover, each filter is symmetric about the axis of motion (see Methods). No further assumptions are made about the structure of the filters.

The model incorporates a fundamental difference between the excitatory and inhibitory branches: while the integrated signals from each excitatory branch are sent directly to the downstream computations, the integrated signals from each inhibitory branch are rectified before being sent downstream. This difference reflects anatomical constraints of the inputs to an actual LPLC2 neuron, where the excitatory inputs are direct connections with LPLC2 while the inhibitory inputs are mediated by inhibitory interneurons (LPi) between LP layers \citep{mauss2015neural,klapoetke2017ultra}. The outputs of the eight branches are summed and rectified to generate the output of a single model unit in response to a given stimulus; see \FIG{model}A.

In the fly brain, a population of LPLC2 neurons converges onto the GF (\FIG{anatomy}D). Accordingly, in our model there are $M$ replicates of model units, with orientations that are spread uniformly over the $4\pi$ steradians of the unit sphere (\FIG{model}C, Methods). In this way, the receptive fields of the $M$ units roughly tile the whole angular space, with or without overlap, depending on the value of $M$. The sum of the responses of the $M$ model units is fed into a sigmoid function to generate the predicted probability of collision for a given trajectory.

\begin{figure}
\includegraphics[width=\linewidth]{figures/model_sketch_paper.pdf}
\caption{Schematic of the model (\nameref{sec:methods}). (A) Single unit. There are two sets of nonnegative filters: excitatory (red) and inhibitory (blue). Each set of filters has four branches, and each branch receives a field of motion signals (forth to seventh rows in \FIG{stimuliFlow}) from the corresponding layer of the model LP. The weighted signals from the excitatory branches and the inhibitory branches (rectified) are pooled together to go through a rectifier to produce an output, which is the response of a single unit. (B) The outputs from $M$ units are summed and fed into a sigmoid function to estimate the probability of hit. (C) The $M$ units have their orientations almost evenly distributed in angular space. Red dots represent the centers of the receptive fields and the grey lines represent the boundaries of the receptive fields on unit sphere. The red lines are drawn from the origin to the center of each receptive field.}
\label{fig:model}
\figsupp[Coordinate system for model and stimuli.]{The coordinate system used in  stimulus generation and modeling (\nameref{sec:methods}). The frame of reference $\Sigma$ is fixed on the fly head. The frame of references $\Sigma_{m}\ (m = 1, 2, \dots, M)$ are associated with each local loom detector, the center of which is represented by a red dot. For $\Sigma_{m}$, only $x_{m}$ and $z_{m}$ are shown, and $y_{m}$ axis should be chosen such that $\Sigma_{m}$ is right-handed. For the unit coordinate systems, $z_{m}$ is chosen to be normal to the unit sphere while $x_{m}$ points north tangent to the sphere. This system does not impose the left-right mirror symmetry of the fly eyes.}{\includegraphics[width=\linewidth]{sup_figures/coordinates_sup_paper.pdf}}\label{figsupp:sf1}
\end{figure}


\subsection{Optimization finds two distinct solutions to the loom-inference problem}

The objective of this study is to investigate how the binary classification task shapes the excitatory and inhibitory filters, and how the number of units $M$ affects the results. We begin with the simplest model, which possess only a single unit, i.e., $M=1$. After training with 200 random initializations of the filters, we find that the converged solutions fall into three broad categories (\FIG{trainedResSingleUnit}A, B). One set of solutions is largely unstructured, with almost all the elements in the filters equal to zero; (labeled in black); we will ignore these for the rest of the analysis. The two structured solutions are interesting because, surprisingly, they have  spatial structures that are roughly opposite from one another (magenta and green). Based on the configurations of the excitatory filters (see Methods), we call one solution type \textit{outward filters}   (magenta), and we called the other type \textit{inward filters} (green) (see \FIG{trainedResSingleUnit}C and \FIGSUPP[trainedResSingleUnit]{sf1}A). In this single-unit model, the inward solutions perform better than the outward solutions on the discrimination task (\FIG{trainedResSingleUnit}D and \FIGSUPP[trainedResSingleUnit]{sf1}B).

As the number of units $M$ increases, the population of cells covers a larger angular space, and when $M$ is large enough (approximately $M=16$), the receptive fields of the units begin to overlap with each other (\FIG{trainedResMultiUnit}A). In the fly visual system there are over 200 LPLC2 neurons across both eyes \citep{ache2019neural}, which corresponds to a very dense distribution of the units. This is illustrated by the third row in \FIG{trainedResMultiUnit}A) where $M=256$. When $M$ is large, approaching objects from any direction are detectable and in fact, such objects signal can be detected simultaneously by many neighboring units. Interestingly, the two oppositely structured solutions persist, regardless of the value of $M$ (\FIG{trainedResMultiUnit},  \FIGSUPP[trainedResMultiUnit]{sf1}, \FIGSUPP[trainedResMultiUnit]{sf2},  \FIGSUPP[trainedResMultiUnit]{sf3}). In some outward solutions, structures on the right side of the inhibitory filters are similar to structures of the corresponding excitatory filters. This indicates a degree of redundancy, or non-identifiability in the model (\FIGSUPP[trainedResMultiUnit]{sf2}, \FIGSUPP[trainedResMultiUnit]{sf3}).

Cells with outward-oriented filters are activated by motion radiating outwards from the center of the receptive field. Thus, these excitatory filters resemble the dendritic structures of the actual LPLC2 neurons observed in experiments, where for example, the rightward motion sensitive branch (LP2) occupies mainly the right side of the receptive field. In the outward solutions, the rightward motion-sensitive inhibitory filter mainly occupies the \textit{left} side of the receptive field. This is also consistent with the properties of the lobula plate intrinsic (LPi) interneurons, which project inhibitory signals roughly retinotopically from one LP layer to an adjacent layer with opposite directional tuning \citep{mauss2015neural,klapoetke2017ultra}.

The unexpected inward-oriented filters have the opposite structure. In the inward solutions, the rightward sensitive excitatory filter occupies the left side of the receptive field, and the inhibitory filter occupies the right side. Such weightings make the model selective for motion converging towards the receptive field center. At first glance, this is a puzzling structure for a loom detector, so we explored the response properties of the inward and outward solutions in more detail.

\begin{figure}
\includegraphics[width=\linewidth]{figures/trained_results_Q1_paper.pdf}
\caption{Two distinct types of models appear from training a single unit on the binary classification task. (A) Clustering of the trained filters/weights shown as a dendrogram (\nameref{sec:methods}). Different colors indicate different clusters, which are preserved for the rest of the paper (see (C)) (B) The trajectories of the loss functions during training. (C) The two distinct types of models are represented by two types of filters that have roughly opposing structure: an outward solution (magenta) and an inward solution (green). The excitatory filter weights are shown in red, and the inhibitory filters are shown in blue. (D) Performance of the two solution types (\nameref{sec:methods}). TPR: true positive rate; FPR: false positive rate; ROC: receiver operating characteristic; PR: precision recall; AUC: area under the curve.}
\label{fig:trainedResSingleUnit}
\figsupp[More examples of the trained filters for the two types of models and the inferred probability of hit for the four types of training stimuli.]{(A) Trained filters: outward model (magenta) and inward model (green). (B) Probability of hit inferred by a single unit for the four types of training stimuli.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_Q1_sup_paper.pdf}}\label{figsupp:sf1}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{figures/trained_results_multicells_paper.pdf}
\caption{The outward and inward solutions also arise for models with multiple units. (A) Left column: angular distribution of the units, where red dots are centers of the receptive fields, the grey circles are the boundaries of the receptive field, and the black star indicates the top of the fly head. Middle column: 2d map of the units with the same symbols as in the left column. Right column: clustering results shown as dendrogams with color codes as in \FIG{trainedResSingleUnit}. (B) Examples of the trained excitatory and inhibitory filters for outward and inward models with different numbers of units.}
\label{fig:trainedResMultiUnit}
\figsupp[Performance of the different solutions.]{Same as in \FIG{trainedResSingleUnit}D) but for models with multiple units.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_multicells_sup1_paper.pdf}}\label{figsupp:sf1}
\figsupp[More examples of the outward filters.]{Outward solutions for models with different numbers of units.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_multicells_sup2_paper.pdf}}\label{figsupp:sf2}
\figsupp[More examples of the inward filters.]{Inward solutions for models with different numbers of  units.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_multicells_sup3_paper.pdf}}\label{figsupp:sf3}
\end{figure}


\subsection{Outward and inward filters are selective to signals in different ranges of angles}

To understand the difference between the two types of solutions and why the inward filters can predict collisions, we investigated how they respond to hit stimuli from different incoming angles $\theta$ (\FIG{compareSingle}A). When there is no signal, the baseline activity of outward units is zero; however, the baseline activity of inward units is above zero (grey dashed lines in \FIG{compareSingle}B, C). This is because the trained intercepts are negative in the outward case, but positive in the inward case (see Methods). Second, as shown in \FIG{compareSingle}B, C, the outward filters respond strongly to stimuli near the center of the receptive field, but do not respond to stimuli having angles larger than $\sim 30^{\circ}$. In contrast, units with inward filters respond negatively to looming stimuli approaching toward the center and positively to stimuli approaching from the periphery of the receptive field, with angles between $\sim 30^{\circ}$ and $\sim 90^{\circ}$ (\FIG{compareSingle}B, C). This helps explain why the inward units can act as loom detectors: they are sensitive to hit stimuli originating in a larger solid angle. The hit signals are isotropic, as shown in \FIG{stimuliTraj}A, so the number of stimuli within angles $\sim 30^{\circ}$ and $\sim 90^{\circ}$ is much larger than the number of stimuli with angles below $\sim 30^{\circ}$ (\FIG{compareSingle}D). Thus, the inward solutions is sensitive to more hit cases than the outward solutions. One may visualize these responses as heat maps of the mean response of the models in terms of object distance to the fly and the incoming angle (\FIG{compareSingle}E). For the hit cases, the response patterns are consistent with the intuition about trajectory angles (\FIG{compareSingle}C). As expected, the inward solutions respond to the retreating signals with angles near $\sim 180^{\circ}$, since the motion of edges in that case is radially inward.

\begin{figure}
\includegraphics[width=\linewidth]{figures/compare_outward_inward_single_unit_paper.pdf}
\caption{The outward and inward filters show distinct behaviors: single unit analysis. (A) Trajectories of hit stimuli with different incoming angles $\theta$. Symbols are the same as in \FIG{stimuliTraj} except that the upward red arrow represents the orientation of one unit. The numbers with degree units indicate the specific values of the incoming angles. (B) Response patterns of a single unit with either outward (magenta) or inward (green) filters obtained from optimized models with 32 and 256 units, respectively. The grey dashed lines show the baseline activity of the unit when there is no stimulus. The solid grey concentric circles correspond to the values of the incoming angles in (A). (C) Temporally averaged responses against the incoming angle $\theta$. Symbols and colors are the same as in (B). (D) Histogram of the incoming angles for the hit stimuli in \FIG{stimuliTraj}A. The grey curve represents a scaled sine function equal to the expected probability for isotropic stimuli. (E) Heatmaps of the response of a single unit against the incoming angle $\theta$ and the distance to the fly head, for both outward and inward filters obtained from optimized models with 32 and 256 units, respectively. A square root was taken on the responses.}
\label{fig:compareSingle}
\end{figure}

\subsection{Outward solutions have sparse codings and populations of units predict accurately the probability of hit}

Individual units of the two models are very different from each other in their filter structure and response patterns to different stimuli. We decided to investigate how these differences manifest in the activities of populations of units, when units are trained to collectively predict the probability of hit. In populations of units, the outward and inward units exhibit very different response patterns for a given hit stimulus (\FIG{compareMulti}A, B). In particular, active outward units usually respond more strongly than inward units, but more inward units will be activated. This is consistent with the findings above, in which inward filter shapes responded to hits arriving from a wider distribution of angles. An exception is the retreat signals, which triggered more active units than the hit signals for the outward solutions (\FIG{compareMulti}). This is because the retreat signals swept through more partial dendritic structures and caused more low level activity (Fig. \FIGSUPP[compareMulti]{sf2}).

When a population of units encodes stimuli, at each time point, the sum of the activities of the units is used to infer the probability of hit. In our trained models, the outward and inward models give similar probabilities of hit (\FIG{compareMulti}A). Both types of models can give accurate inferences for the different stimuli (\FIG{compareMulti}C). In some cases, misses can be very similar to hits if the object passes near the origin. The models reflect this in their responses to near misses which have higher hit probabilities than far misses (\FIG{compareMulti}D).

\begin{figure}
\begin{fullwidth}
\includegraphics[width=\linewidth]{figures/compare_outward_inward_multiple_units_paper.pdf}
\caption{Population coding of stimuli. (A) Top row: a snapshot of the responses of outward units (magenta dots) for a hit stimulus (grey shade). Symbols and colors are as in \FIG{trainedResMultiUnit}A. Middle row: the whole trajectories of the responses for the same hit stimulus as in the top row. Bottom row: the entire trajectories of the probability of hit for the same hit stimulus as in the top row (\nameref{sec:methods}). Black dots in the middle and bottom rows indicate the time step of the snapshot in the top row. (B) Fractions of the units that are activated by different types of stimuli (hit, miss, retreat, rotation) as a function of the number of units $M$ in the model. The lines represent the mean values averaged across samples, and the shaded areas show one standard deviation. (C) Histograms of the probability of hit inferred by models with 32 or 256 units for the four types of synthetic stimuli (\nameref{sec:methods}). (D) The inferred probability of hit as a function of the minimum distance of the object to the fly eye for the miss cases. The hit distribution is represented by a box plot with [DEFINE BOX and whiskers features in percentiles!]}
\label{fig:compareMulti}
\figsupp[Geometry of responses (as in Fig. \FIG{compareMulti}A), but for miss and retreat stimuli.]{(A) An example of response patterns to a miss stimulus. (B) An example of response patterns to a retreat stimulus.}{\includegraphics[width=\linewidth]{sup_figures/compare_outward_inward_multiple_units_sup_paper.pdf}}\label{figsupp:sf1}
\figsupp[Sample individual unit response curves.]{(A) Sample response curves of the active units in the outward solution with $M=256$ for different types of stimuli (from left to right: Hit, Miss, Retreat, Rotation) (B) As in (A), but for an inward solution.}{\includegraphics[width=\linewidth]{sup_figures/compare_outward_inward_multiple_units_sup2_paper.pdf}}\label{figsupp:sf2}
\end{fullwidth}
\end{figure}


\subsection{Large populations of units improve performance and favor outward filters}

Since a larger number of units will cover an increasing spatial area of the visual field, the population of units can in principle provide more information about the incoming signals. In general, the models perform better as the number of units $M$ increases (\FIG{outwardPrevail}A). When $M$ is above 32, both the ROC-AUC and PR-AUC scores are almost 1 (see Methods), which indicates that the model is very accurate on the binary classification task presented by the four types of synthetic stimuli.

In addition, we calculated the ratio of the number of outward filters to inward filters that arise out of 200 random initializations in models with $M$ units, as we swept $M$. Interestingly, as the number of units increased, an increasing proportion of solutions had outward filters (\FIG{outwardPrevail}B). For models with 256 units, the chance that an outward filter appears as a solution is almost four times larger than when $M=1$. Indeed, although both outward and inward models with large $M$ have similar ROC-AUC and PR-AUC scores,  the outward filters have lower cross entropy loss for large populations of units (\FIG{outwardPrevail}C). These results suggest that when there are many units, optimization favors the outward solution, both in terms of performance and in the likelihood of finding a specific solution.

\begin{figure}
\includegraphics[width=\linewidth]{figures/outward_better_than_inward_paper.pdf}
\caption{Large populations of units improve performances and favor outward models (\nameref{sec:methods}). (A) Both ROC and PR AUC scores increase as the number of units increases. Lines and dots: average scores; shading: one standard deviation of the scores over the trained models. Magenta: outward models; green: inward models. (B) The black line and dots show the ratio of the numbers of the two types of the solution in the set of randomly initialized, trained models. The grey shading is one standard deviation, assuming that the distribution is binomial. The dotted horizontal line indicates the ratio of 1. (C) AS the population of units increases, cross entropy losses of the outward solutions become lower than the inward solutions.}
\label{fig:outwardPrevail}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[Same as in Fig. \FIG{outwardPrevail}A,B but for training in different conditions.]{(A) A different probability model (\nameref{sec:methods}). (B) Training without rotation stimuli. (C) Training with larger distances of the objects to the fly eye.}{\includegraphics[width=\linewidth]{sup_figures/outward_better_than_inward_sup_paper.pdf}}\label{figsupp:sf1}
\end{figure}

\subsection{Activation patterns of computational solutions resemble biological responses}

The outward models have a receptive field structure that is similar to LPLC2 neurons, based on their anatomy and functional studies. However, it is not clear whether these models possess the functional properties of LPLC2 neurons, which have been studied systematically \citep{klapoetke2017ultra,von2017feature,ache2019neural}. To see how trained units compare to LPLC2 neuron properties, we presented stimuli to the trained model (\FIG{replication}A) to compare its responses to those measured in LPLC2 to similar stimuli.

The model behaves similarly to LPLC2 neurons on many different types of stimuli. Not surprisingly, the model is selective to loom signals and does not have strong responses to non-looming signals (\FIG{replication}B). Moreover, the model closely follows the response of LPLC2 neurons to various expanding bar stimuli, including the inhibitory effects of inward motion (\FIG{replication}C, D). In addition, in experiments, motion signals that appear at the periphery of the receptive field suppress the activity of the LPLC2 neurons (periphery inhibition) \citep{klapoetke2017ultra}, and this phenomenon is successfully predicted by the model (\FIG{replication}E, F) due to the broad inhibitory filters that the model learns (\FIG{replication}A). Interestingly, the model also correctly predicts response patterns of the LPLC2 neurons for expanding bars with different orientations (\FIG{replication}G, H). 
The ratio of object size to approach velocity, or $R/v$, is an important parameter for looming stimuli, and many studies have investigated how the response patterns of loom-sensitive neurons depend on this ratio (Top panels in \FIG{replication}I, J, K, L) \citep{gabbiani1999computation,von2017feature,ache2019neural}. Here, we presented the trained model (\FIG{replication}A) with hit stimuli with different $R/v$ ratios, and compared its behaviors with the experimental data (\FIG{replication}I-L)). Surprisingly, although our model only has the angular velocities as the inputs (\FIG{stimuliFlow}), it reliably encodes the angular sizes rather than the angular velocities, indicated by the collapsed response curves (up to different scales) when plotted against the angular sizes (\FIG{replication}J) \citep{von2017feature}. On the contrary, for angular velocities, the response curves shift for different $R/v$ ratios, which means they depend on the velocities $v$ of the object ($R$ is fixed to be 1). Both of these response properties are consistent with properties of LPLC2. Meanwhile, a canonical linear relationship between the peak response time relative to the collision and the $R/v$ ratio was also reproduced by the optimized model (\FIG{replication}L) \citep{gabbiani1999computation,ache2019neural}. 

Importantly, a different outward solution from the same training procedure could reproduce many of the same effects (\FIGSUPP[replication]{sf1}), but it predicts the patterns in the wide expanding bars differently and out of phase from the biological data (\FIGSUPP[replication]{sf1}H). This different solution also does a poor job predicting the response curves of the LPLC2 neurons to looming signals with different $R/v$ ratios, although the collapsed and shifted features remain when plotted as functions of angular size and velocity (\FIGSUPP[replication]{sf1}J, K). This shows that even within the family of learned outward models, there is variability in the learned response properties. Though solving the inference problem obtains many of the response properties, additional constraints would be required to more precisely reproduce the LPLC2 responses.

\begin{figure}
\begin{fullwidth}
\includegraphics[width=\linewidth]{figures/replication_paper.pdf}
\caption{Models trained on binary classification tasks exhibited similar responses to LPLC2 neurons observed in experiments. (A) Excitatory and inhibitory filters of an outward solution with 256 units. (B-H) Comparisons of the responses of the solution in (A) and LPLC2 neurons to a variety of stimuli. Black lines: data \citep{klapoetke2017ultra}; magenta lines: model. Compared with the original plots \citep{klapoetke2017ultra}, all the stimuli icons here except the ones in (B) have been rotated 45 degrees to match the cardinal directions of LP layers as described in this study. (I) Top: temporal trajectories of the angular sizes for different $R/v$ ratios (color labels apply throughout (I-L).). Middle: response as function of time for the sum of all 256 units. Bottom: responses as function of time for one of the 256 units. (J-L) Top: experime
newtal data (LPLC2/non-LC4 components of GF activity. Data from \citep{von2017feature,ache2019neural}). Middle: sum of all 256 units. Bottom: response of one of the 256 units. Responses as function of angular size (J), response as function of angular velocity (K), relationship between peak time relative to collision and $R/v$ ratios (L). We considered the first peak when there were two peaks in the response, such as in the grey curves in the middle panel of (I).}
\label{fig:replication}
\figsupp[Same as in the main figure but for a different outward model obtained from the same training procedure.]{The same as the main figure for a different trained outward model, the filters of which are shown in (A).}{\includegraphics[width=\linewidth]{sup_figures/replication_sup1_paper.pdf}}\label{figsupp:sf1}
% \figsupp[Same as in the main figure but for summed HRC outputs instead of model responses.]{The same as the second and the third rows of the I-L in the main figure but for the simple sum of the motion fields (outputs of the HRC). First row: the sum of HRC outputs received by a single unit; the black vertical line in the second panel indicates $60^{\circ}$, which is the size of the receptive field of a single model unit. Second row: the sum of HRC outputs received by all units ($M=256$).}{\includegraphics[width=\linewidth]{sup_figures/replication_sup2_paper.pdf}}\label{figsupp:sf2}
\end{fullwidth}
\end{figure}

\video{Movie for a hit stimulus (single unit). Top left panel: 3d rendering as in the top row of \FIG{stimuliFlow}; bottom left panel: optical signal as in the second row of \FIG{stimuliFlow}; top right panel: flow fields in the horizontal direction as in rows 7 and 8 of \FIG{stimuliFlow}; bottom right panel: flow fields in the vertical direction as in rows 5 and 6 of \FIG{stimuliFlow}. Since we combined left (down) and right (up) flow fields in one panel, we used blue and red colors to indicate left (down) and right (up) directions, respectively.}\label{video:hit_single}

\video{Movie for a hit stimulus (outward model with multiple units, where $M=32$). Top left panel: the same as in the top row of \FIG{compareMulti}A;  bottom left, top right, bottom left panels: the same as in \VIDEO{hit_single} but with more units.}\label{video:hit_multi_outward}

\video{Movie for a hit stimulus (inward model with multiple units, where $M=32$). The same as \VIDEO{hit_multi_outward} but for an inward model.}\label{video:hit_multi_inward}


\section{Discussion}

In this study, we have shown that training a simple network to detect collisions gives rise to a computation that closely resembles neurons that are sensitive to loom. Specifically, we optimized a neural network model to detect whether an object is on a collision course based on the visual motion signals (\FIG{stimuliFlow}), and found that one class of optimized solution matched the anatomy of motion inputs to LPLC2 neurons (\FIG{anatomy}, \FIG{trainedResSingleUnit}, \FIG{trainedResMultiUnit}). Importantly, this solution can reproduce a large range of experimental observations of LPLC2 neuron responses (\FIG{replication}) \citep{klapoetke2017ultra,von2017feature,ache2019neural}.]

The radially structured dendrites of the LPLC2 neuron in the lobula plate can account for its response to motion radiating outward from the receptive field center \citep{klapoetke2017ultra}. Our results show that the logic of this computation can be understood in terms of inferential loom detection by the \textit{population} of units. In particular, for an individual detector unit, an inward structure makes a better loom detector than an outward structure, since it is sensitive to looming objects originating from a wider array of incoming angles (\FIG{compareSingle}). As the number of units across visual space increases, the outward-sensitive receptive field structure is represented more often in the optimal solution. The solution depends on the number of detectors because the receptive fields increasingly overlap as the population grows (\FIG{trainedResMultiUnit}). This result is consistent with prior work showing that populations of neurons often exhibit different and improved coding strategies compared to individual neurons \citep{pasupathy2002population,georgopoulos1986neuronal,vogels1990population,franke2016structures,zylberberg2016direction,cafaro2020global}. Thus, understanding anatomical, physiological, and algorithmic properties of individual neurons can require considering the population response. The solutions we found to the loom inference problem suggest that individual LPLC2 responses should be interpreted in light of the population of LPLC2 responses.

Surprisingly, the trained outward model exhibits the properties of an angular size encoder (\FIG{replication}I-L), even though the inputs to the model are a field of motion signals. There are two ways that this tuning arises. First, in a looming stimulus, the angular size and angular velocity are strongly correlated \citep{gabbiani1999computation}, which means the angular size affects the magnitude of the motion signals. Second, the angular size is proportional to length of the outward-moving edges of looming objects. The angular circumference of the looming stimulus determines how many motion detector are activated, so that integrated motion signal strength is related to size. Both of these effects influence the response patterns of the model units (and the LPLC2 neurons). 
%[In fact, if one looks at the total flow field (HRC %outputs) received by a single unit, they show similar %'tuning' properties and linear relationships as the GF and %the model responses (\FIGSUPP[replication]{sf2}). More %interestingly, the total flow fields received by all model %units ($M=256$) do not show the same pattern, which means %some nonlinear tranformation must have been applied to the %inputs (\FIGSUPP[replication]{sf2}). One possible reason of %this nonlinearity could be the orientations of the filters %of the model units. This remains an interesting question %for future investigations.] 
Our results shed light on discussions of $\eta$-like (encoding angular size) and $\rho$-like (encoding angular velocity) looming sensitive neurons in the literature \citep{gabbiani1999computation,wu2005tectal,liu2011neuronal,shang2015parvalbumin,temizer2015visual,dunn2016neural,von2017feature,ache2019neural}. In particular, these optimized models clarify an interesting but puzzling fact: LPLC2 neurons transform their inputs of direction-selective motion signals to computations of angular size \citep{ache2019neural}. Consistently, our model shows the linear relationship between the peak time relative to collision and the $R/v$ ratio, which looming sensitive neurons that encode angular size should follow \citep{peek2016comparative}. In both cases, these properties appear to be the simple result of training the constrained model to reliably detect looming stimuli.

The units of the outward model exhibit sparsity in their responses to looming stimuli, in contrast to the denser representations in the inward model (\FIG{compareMulti}). During a looming event, most of the units are quiet and only a few adjacent units have very large activities, reminiscent of sparse codes that seem to be favored, for instance, in cortical encoding of visual scenes \citep{olshausen1996emergence,olshausen1997sparse}. Since the readout of our model is a summation of the activities of the units, sparsity does not directly affect the performance of the model, but is an attribute of the favored solution. For a model with a different loss function or noise, the degree of sparsity might be crucial. For instance, the sparse code of the outward model might make it easier to localize the loom stimulus \citep{morimoto2020spatial}, or might make the population response more robust to noise \citep{field1994goal}. 

Experiments have shown that inhibitory circuits play an important role for the selectivity of LPLC2 neurons. For example, motion signals at the periphery of the receptive field of an LPLC2 neuron inhibit its activity; such peripheral inhibition causes various interesting response patterns of the LPLC2 neurons to different types of stimuli \citep{klapoetke2017ultra}. However, the structure of this inhibitory field is not fully understood, and our model provides a tool to investigate how the inhibitory inputs to LPLC2 neurons affect circuit performance on loom detection tasks. Specifically, strong inhibition on the periphery of the receptive field arises naturally in the outward solutions after optimization \citep{klapoetke2017ultra}. The broad inhibition appears in our model to suppress responses to the non-hit stimuli. As in the data, the inhibition is broader than one might expect if the neuron were simply being inhibited by inward motion.

The synthetic stimuli used to train models in this study were unnatural in two ways. The first way was in the proportion of hits and non-hits. We trained with 25\% of the training data representing hits. The true fraction of hits among all stimuli encountered by a fly is undoubtedly much less, and this affects how the loss function weights different types of errors. It is also clear that a false-positive hit (in which a fly might jump to escape an object not on collision course) is much less penalized during evolution than a false-negative (in which a fly doesn't jump and an object collides, presumably to the detriment of the fly). It remains unclear how to choose these weights in the training data or in the loss function, but they affect the receptive field weights optimized by the model.

The second issue with the stimuli is that they were caricatures of stimulus types, but did not incorporate the richness of natural stimuli. This richness could include natural textures and spatial statistics \citep{ruderman1994statistics}, which seem to impact motion detection algorithms \citep{fitzgerald2015nonlinear,leonhardt2016asymmetry,chen2019asymmetric}. This richness could also include more natural trajectories for approaching objects. Another way to enrich the stimuli would be to add noise, either in inputs to the model or in the model's units themselves. These aspects of the stimuli were all neglected in this initial study, in part because it is difficult to find characterizations of natural loom events. An interesting future direction will be to investigate the effects of more complex and naturalistic stimuli on the model's filters and performance, as well as on LPLC2 neuron responses themselves. 
For simplicity, this model did not impose the hexagonal geometry of the compound eye ommatidia. Instead, we assume that the visual field is separated into a Cartesian lattice with $5^{\circ}$ spacing, each representing a local motion detector with two spatially separated inputs (\FIG{stimuliFlow}). This simplification alters slightly the geometry of the motion signals compared to the real motion detector receptive fields \citep{shinomiya2019comparisons}. This could potentially affect the learned spatial weightings and reproduction of the LPLC2 responses to various stimuli, since the specific shapes of the filters matter (\FIG{replication}). Thus, the hexagonal ommatidial structure and the full extent of inputs to T4 and T5 might be crucial if one wants to make comparisons with the dynamics and detailed responses of LPLC2 neurons. However, this geometric distinction seems unlikely to affect the main results of how to infer the presence of looming stimuli.

Our model requires a field of estimates of the local motion. Here, we used the simplest model -- the Hassenstein-Reichardt correlator model \EQ{HRC} \citep{hassenstein1956systemtheoretische} -- but the model could be extended by replacing it with a more sophisticated model for motion estimation. Some biophysically realistic ones might take into account synaptic conductances \citep{gruntman2018simple,gruntman2019computation,badwan2019dynamic,zavatone2020minimal}. Alternatively, in natural environments, contrasts fluctuate in time and space. Thus, if one includes more naturalistic spatial and temporal patterns, one might consider a motion detection model that can adapt to changing contrasts in time and space  \citep{drews2020dynamic,matulis2020heterogeneous}. The tuning curve of any motion estimator depends on the spatial offsets of the inputs and the timescales of the temporal filters. A relevant quantity for looming stimuli is the $R/v$ ratio, where $R$ is the radius of the object and  $v$ is the velocity at which the object is moving. The ratio determines a timescale for the expansion of a looming object on a collision course, in which a short timescale corresponds to a fast-moving object. In our simulations, we kept the ratio in a range that makes the HRC output roughly proportional to the velocity (\EQ{HRC}, \FIGSUPP[stimuliFlow]{sf1}).

Our neural network model is highly constrained by the specific anatomy of LPLC2 circuits, and no unnecessary layers were added. The resulting model is a shallow neural network (\FIG{anatomy} and \FIG{model}. This shallowness leads to limited dimensionality of the model, which will be prone to finding non-optimal local minima during training. Indeed, in many cases, the training resulted in models with poor performance and filters with weights very close to zero. We minimized this problem by choosing the initialization scales for the filters so that optimization resulted in meaningful models with structured filters about half of the time. However, the ratio of the outward and inward solutions (\FIG{outwardPrevail}B) was not affected by the initialization scales.

Although the outward filter of the unit emerges naturally from our gradient descent training protocol, that does not mean that the structure is learned by LPLC2 neurons in the fly. There is some experience dependent plasticity in the fly eye \citep{kikuchi2012experience}, but these visual computations are likely to be primarily genetically determined. Thus, one could think of the computation of the LPLC2 neuron as being shaped through millions of years of evolution. Interestingly, optimization algorithms similar to evolution may be able to avoid getting stuck in local optima \citep{stanley2019designing}, and thus work well with the sort of shallow neural network found in the fly eye.

In this study, we focused on the motion signal inputs to LPLC2 neurons, and we neglected other inputs to LPLC2 neurons, such as inputs coming from the lobula that likely report non-motion visual features. It would be interesting to investigate how this additional non-motion information would affect the performance and optimal solutions of the inference units. For instance, another lobula columnar neurons, LC4, is loom sensitive and receives inputs in the lobula \citep{von2017feature}. The LPLC2 and LC4 neurons are the primary excitatory inputs to the GF, which mediates the escape behavior of a fly \citep{von2014spike, ache2019neural}. The inference framework set out here would allow one to incorporate of parallel non-motion intensity channels, either by adding them into the inputs to the LPLC2-like units, or by adding in a parallel population of LC4-like units. This would require a reformulation of the probabilistic model in \EQ{prob_model}. Notably, one of the most studied loom detecting neurons, the lobula giant movement detector (LGMD) in locusts, does not appear to receive direction-selective inputs, as LPLC2 does \citep{rind1996neural,gabbiani1999computation}. Thus, the inference framework set out here can be flexibly modified to investigate loom detection under a wide variety of constraints and inputs, which allow it to be applied to other neurons, beyond LPLC2. 

\newpage

\section{Methods and Materials}
\label{sec:methods}

\subsection{Code availability}
Code to perform all simulations in this paper and to reproduce all figures is available at \\ http://www.github.com/ClarkLabCode/XXXXX.

\subsection{Coordinate system and stimuli}


We designed a suite of visual stimuli to simulate looming objects, retreating objects, and rotational visual fields. In this section, we describe the suite of stimuli and the coordinate systems used in our simulations.

In our simulations and training, the fly is at rest on a horizontal plane, with its head pointing in a specific direction. The fly head is modeled to be a point particle with no volume. A three dimensional right-handed frame of reference $\Sigma$ is set up and attached to the fly head at the origin. The $z$ axis points in the anterior direction from the fly head, perpendicular to the line that connects the two eyes, and in the horizontal plane of the fly; the $y$ axis points toward the right eye, also in the horizontal plane; and the $x$ axis points upward and perpendicular to the horizontal plane. Looming or retreating objects are represented in this space by a sphere with radius $R=1$, and the coordinates of an object's center at time $t$ are denoted as $\mathbf{r}(t) = (x(t),y(t),z(t))$. Thus, the distance between the object center and the fly head is $D(t) = \|\mathbf{r}(t)\| = \sqrt{x^{2}(t)+y^{2}(t)+z^{2}(t)}$.

Within this coordinate system, we set up cones to represent individual units. The receptive field of LPLC2 neurons is measured at roughly 60-degree in diameter \citep{klapoetke2017ultra}. Thus, we here model each unit as a cone with its vertex at the origin and with half-angle of 30 degrees. The orientation of the axis of the cone can be characterized by two of the Euler angles $\psi$ (around $z$) and $\theta$ (around the new $x^{'}$ axis after the rotation around $z$) with respect to the frame of reference. For each unit $m$ ($m=1, 2, \dots, M$), we set up a local frame of reference $\Sigma_{m}$ (\FIGSUPP[model]{sf1}): the $z_{m}$ axis is the axis of the cone and its positive direction points outward from the origin, the $x_{m}$ axis lies in the plane spanned by the $x$ axis of $\Sigma$ and the $z_{m}$ axis of $\Sigma_{m}$ and has an acute angle with the positive direction of $x$ axis of $\Sigma$, and the $y_{m}$ axis should be chosen such that $\Sigma_{m}$ is right-handed. For each unit, its cardinal directions are defined as: upward (positive direction of $x_{m}$), downward (negative direction of $x_{m}$), leftward (negative direction of $y_{m}$ and rightward (positive direction of $y_{m}$. To get the signals that are received by a specific unit $m$, the coordinates of the object in $\Sigma$ are rotated to the local frame of reference $\Sigma_{m}$.

Within this coordinate system, we can set up cones representing the extent of a spherical object moving in the space. The visible outline of a spherical object spans a cone with its point at the origin. The half-angle of this cone is a function of time and can be denoted as $\theta_{\text{s}}(t)$:
\begin{equation}
\theta_{\text{s}}(t) = \arcsin{\frac{R}{D(t)}}.
\end{equation}
One can calculate how the cone of the object overlaps with the receptive field cones of each unit.

There are multiple layers in the fly visual system \citep{takemura2017comprehensive}, but here we focus on two coarse grained stages of processing: (1) the estimation of local motion direction from optical intensities by motion detection neurons T4 and T5 and (2) the integration of the flow fields by LPLC2 neurons. In our simulations, the interior of the $m$th unit cone is represented by a $N$-by-$N$ matrix, so that each element in this matrix indicates a specific direction in the angular space within the unit cone. If an element also falls within the object cone, then its value is set to 1; otherwise it is 0. Thus, at each time $t$, this matrix is an optical contrast signal and can be represented by $C(x_{m},y_{m},t)$, where $(x_{m},y_{m})$ are the coordinates in $\Sigma_{m}$. In general, $N$ should be large enough to provide good angular resolutions. Then, $K^{2}$ ($K<N$) motion detectors are evenly distributed within the LPLC2 cone, with each occupying an $L$-by-$L$ grid in the $N$-by-$N$ matrix, where $L=N/K$. This $L$-by-$L$ grid represents a $5^{\circ}$-by-$5^{\circ}$ square in the angular space, consistent with the approximate spacing of the inputs of motion detectors T4 and T5. This arrangement effectively upsamples the spatial resolution of the intensity data before it is discretized into motion signals with $5^{\circ}$. Since the receptive field of an LPLC2 neuron is roughly $60^{\circ}$, the value of $K$ is chosen to be 12. To get sufficient angular resolution for the local motion detectors, $L$ is set to be 4, so that $N$ is set to 48.

Each motion detector is assumed to be a Hassenstein Reichardt Correlator (HRC) and calculates local flow fields from $C(x_{m},y_{m},t)$ \citep{hassenstein1956systemtheoretische}. The HRC used here has two inputs, separated by $5^{\circ}$ in angular space. Each input applies first a spatial filter on the contrast $C(x_{m},y_{m},t)$ and then temporal filters:
\begin{align}
I_{j}(t;x_{m},y_{m}) = \sum_{t^{'}=0}^{t}\sum_{x^{'}_{m}=-N}^{N}\sum_{y^{'}_{m}=-N}^{N}f_{j}(t^{'})G(x^{'}_{m},y^{'}_{m})C(x_{m}-x^{'}_{m},y_{m}-y^{'}_{m},t-t^{'}),
\end{align}
where $f_{j}\ (j \in {1,2})$ is a temporal filter and $G$ is a discrete 2d Gaussian kernel with mean $0^{\circ}$ and standard deviation of $2.5^{\circ}$ to approximate the acceptance angle of the fly photoreceptors \citep{stavenga2003angular}. For simplicity, the temporal filters $f_{1}$ and $f_{2}$ were chosen to be delta functions, $f_{1}(t^{'})=\delta (t^{'}-(t-\Delta))$ and $f_{2}=\delta (t^{'}-t)$, one peaking after a delay $\Delta$, the other peaking at the current time $t$, with $\Delta$ set to 0.03 seconds \citep{salazar2016direct}. This leads to
\begin{align}\label{eq:HRC}
F(t;x_{m1},y_{m1},x_{m2},y_{m2}) = I_{1}(t;x_{m1},y_{m1})I_{2}(t;x_{m2},y_{m2})-I_{1}(t;x_{m2},y_{m2})I_{2}(t;x_{m1},y_{m1}).
\end{align}
as the local flow field at time $t$ between two inputs located at $(x_{m1},y_{m1})$ and $(x_{m2},y_{m2})$.

Four types of T5 neurons have been found that project to layers 1, 2, 3, and 4 of the lobula plate. Each type is sensitive to one of the cardinal directions: down, up, left, right \citep{maisak2013directional}. Thus, in our model, there are four nonnegative, local flow fields that serve as the only inputs to the model: $U_{-}(t)$ (downward, corresponding LP layer 4), $U_{+}(t)$ (upward, LP layer 3), $V_{-}(t)$ (leftward, LP layer 1) and $V_{+}(t)$ (rightward, LP layer 2), each of which is a $K$-by-$K$ matrix. To calculate these matrices, two sets of motion detectors are needed, one for the vertical directions and one for the horizontal directions. The HRC model in \EQ{HRC} is direction sensitive and is opponent, meaning that for motion in the preferred (null) direction, the output of the HRC model is positive (negative). Thus, assuming that upward (rightward) is the preferred vertical (horizontal) direction, we obtain the elements of the four flow fields as
\begin{align*}
[U_{-}(t)]_{k_{1}k_{2}} &= \lvert \min(0,F(t;x_{m1},y_{m},x_{m2},y_{m})) \rvert \nonumber \\
[U_{+}(t)]_{k_{1}k_{2}} &= \lvert \max(0,F(t;x_{m1},y_{m},x_{m2},y_{m})) \rvert \nonumber \\
[V_{-}(t)]_{k_{1}k_{2}} &= \lvert \min(0,F(t;x_{m},y_{m1},x_{m},y_{m2})) \rvert  \nonumber \\
[V_{+}(t)]_{k_{1}k_{2}} &= \lvert \max(0,F(t;x_{m},y_{m1},x_{m},y_{m2})) \rvert,
\end{align*}
where $k_{1},k_{2} \in \{1,2,\dots,K\}$ and $\lvert \cdot \rvert$ represents the absolute value. In the above expressions, it implies, for $[U_{-}(t)]_{k_{1}k_{2}}$ and $[U_{+}(t)]_{k_{1}k_{2}}$, the vertical motion detector at $(k_{1},k_{2})$ has its two inputs located at $(x_{m1},y_{m})$ and $(x_{m2},y_{m})$, respectively. Similarly, for for $[V_{-}(t)]_{k_{1}k_{2}}$ and $[V_{+}(t)]_{k_{1}k_{2}}$, the horizontal motion detector at $(k_{1},k_{2})$ has its two inputs located at $(x_{m},y_{m1})$ and $(x_{m},y_{m2})$. Using the opponent HRC output as the motion signals for each layer is reasonable because the motion detectors T4 and T5 are highly direction-selective over a large range of inputs \citep{maisak2013directional, creamer2018} and synaptic, 3-input models for T4 are approximately equivalent to opponent HRC models \citep{zavatone2020minimal}.

We simulated the trajectories $\mathbf{r}(t)$ of the object in the frame of reference $\Sigma$ at a time resolution of 0.01 seconds. For hit, miss, and retreat cases, the trajectories of the object are always straight lines (i.e., ballistic motion), and the velocities of the object were randomly sampled from a range $[2R,10R](s^{-1})$ with the trajectories confined to be within a sphere of $5R$ centered at the fly head. The radius of the object, $R$, is always set to be 1 except in the rotational stimuli. To generate rotational stimuli, we placed 100 objects with various radii randomly selected from $[0,1]$ at random positions ([5, 15]) around the fly, and rotated them all around a specific axis. The rotational speed was chosen from a Gaussian distribution with mean $0^{\circ}/s$ and standard deviation $200^{\circ}/s$, a reasonable rotational velocity for walking flies \citep{deangelis2019manifold}.


\subsection{Models}
Experiments have shown that an LPLC2 neuron has four dendritic structures in the four LP layers, and that they receive direct excitatory inputs from T4/T5 motion detection neurons \citep{maisak2013directional,klapoetke2017ultra}. It has been proposed that each dendritic structure also receives inhibitory inputs mediated by lobulate plate intrinsic interneurons, such as LPi4-3 \citep{klapoetke2017ultra}. Accordingly, our models have two types of nonnegative filters, one excitatory and one inhibitory (\FIG{model}, represented by $W^{\text{e}}$ and $W^{\text{i}}$, respectively. Each filter is a $12$-by-$12$ matrix. We rotate $W^{\text{e}}$ and $W^{\text{i}}$ counterclockwise by multiples of $90^{\circ}$ to obtain the filters that are used to integrate the four motion signals: $U_{-}(t)$, $U_{+}(t)$, $V_{-}(t)$, $V_{+}(t)$. Specifically, we define the corresponding four excitatory filters as: $W^{\text{e}}_{U_{-}}=\text{rotate}(W^{\text{e}},270^{\circ})$, $W^{\text{e}}_{U_{+}}=\text{rotate}(W^{\text{e}},90^{\circ})$, $W^{\text{e}}_{V_{-}}=\text{rotate}(W^{\text{e}},180^{\circ})$, $W^{\text{e}}_{V_{+}}=\text{rotate}(W^{\text{e}},0^{\circ})$, and the inhibitory filters as: $W^{\text{i}}_{U_{-}}=\text{rotate}(W^{\text{i}},270^{\circ})$, $W^{\text{i}}_{U_{+}}=\text{rotate}(W^{\text{i}},90^{\circ})$, $W^{\text{i}}_{V_{-}}=\text{rotate}(W^{\text{i}},180^{\circ})$, $W^{\text{i}}_{V_{+}}=\text{rotate}(W^{\text{i}},0^{\circ})$. In addition, we impose mirror symmetry to the filters, and with the above definitions of the rotated filters, the upper half of $W^{\text{e}}$ is a mirror image of the lower half of $W^{\text{e}}$. The same mirror symmetry applies to $W^{\text{i}}$. Thus, there are in total 144 parameters in the two sets of filters. In fact, since only the elements within a 60 degree cone contribute to the filter for the units, the corners are excluded, resulting in only 112 trainable parameters in the excitatory and inhibitory filters.

In computer simulations, the weights and flow fields are flattened to be one-dimensional column vectors. The responses of the inhibitory units are:
\begin{align*}
r^{\text{i}}_{U_{-}}(t) &= \phi \left( (W^{\text{i}}_{U_{-}})^{T}U_{-}(t)+b^{\text{i}} \right) \nonumber \\
r^{\text{i}}_{U_{+}}(t) &= \phi \left( (W^{\text{i}}_{U_{+}})^{T}U_{+}(t)+b^{\text{i}} \right) \nonumber \\
r^{\text{i}}_{V_{+}}(t) &= \phi \left( (W^{\text{i}}_{V_{+}})^{T}V_{+}(t)+b^{\text{i}} \right) \nonumber \\
r^{\text{i}}_{V_{-}}(t) &= \phi \left( (W^{\text{i}}_{V_{-}})^{T}V_{-}(t)+b^{\text{i}} \right),
\end{align*}
where $\phi(\cdot) = \max(\cdot,0)$ is the rectified linear activation function, and $b^{\text{i}} \in \mathbb{R}$ is the intercept.
The response of a single unit $m$ is
\begin{multline}\label{eq:LPLC2_response}
r_{m}(t) = \phi \Bigg( (W^{\text{e}}_{U_{-}})^{T}U_{-}(t)+(W^{\text{e}}_{U_{+}})^{T}U_{+}(t)+(W^{\text{e}}_{V_{+}})^{T}V_{+}(t)+(W^{\text{e}}_{V_{-}})^{T}V_{-}(t)- \\
\left(r^{\text{i}}_{U_{-}}(t)+r^{\text{i}}_{U_{+}}(t)+r^{\text{i}}_{V_{+}}(t)+r^{\text{i}}_{V_{-}}(t)\right)+b^{\text{e}} \Bigg),
\end{multline}
where $b^{\text{e}} \in \mathbb{R}$ is the intercept (\FIG{model}).
The inferred probability of hit for a specific trajectory is
\begin{equation}
\hat{P}_{\text{hit}} =\frac{1}{T}\sum_{t=1}^{T} \sigma \left( \sum_{m}r_{m}(t)+b \right),
\label{eq:prob_model}
\end{equation}
where $T$ is the total number of time steps in the trajectory and $\sigma(\cdot)$ is the sigmoid function. Since we are adding three intercepts $b^{\text{i}}$,$b^{\text{e}}$, and $b$, there are 115 parameters to train in this model.

% Variations of the above model were also tested. The first variation introduces a modified probability model compared with \EQ{prob_model}:
% \begin{equation}
% \hat{P}^{'}_{\text{hit}} = \frac{1}{T}\sum_{t=1}^{T}\left\{ 2\sigma \left( \sum_{m}r_{m}(t) \right)-1 \right\}.
% \label{eq:prob_model2}
% \end{equation}

% A second variation we tested is a modification of \EQ{LPLC2_response}, where the inhibitory units are deleted and the filters, represented by $W^{\text{'}}_{U_{-}},W^{\text{'}}_{U_{+}},W^{\text{'}}_{V_{+}},W^{\text{'}}_{V_{-}}$, are allowed to have both positive and negative values, i.e.,
% \begin{equation}
% r_{m}^{'}(t) = \phi \left( (W^{\text{'}}_{U_{-}})^{T}U_{-}(t)+(W^{\text{'}}_{U_{+}})^{T}U_{+}(t)+(W^{\text{'}}_{V_{+}})^{T}V_{+}(t)+(W^{\text{'}}_{V_{-}})^{T}V_{-}(t)+b^{'} \right).
% \label{eq:LPLC2_response_2}
% \end{equation}

\subsection{Training and testing}
We created a synthetic data set containing four types of motion: \emph{loom-and-hit}, \emph{loom-and-miss}, \emph{retreat}, and \emph{rotation}. The proportions of these types were 0.25, 0.125, 0.125, and 0.5, respectively. In total, there were 5200 trajectories, with 4,000 for training and 1,200 for testing. Trajectories with motion type \emph{loom-and-hit} are labeled as hit or $y_{n}=1$ (probability of hit is 1), while trajectories of other motion types are labeled as non-hit or $y_{n}=0$ (probability of hit is 0), where $n$ is the index of each specific sample. Models with smaller $M$ have fewer trajectories in the receptive field of any unit. For stability of training, we therefore increased the number of trajectories by factors of eight, four, and two for $M=1, 2, 4$, respectively.

The loss function to be minimized in our training was the cross entropy between the label $y_{n}$ and the inferred probability of hit $\hat{P}_{\text{hit}}$, and averaged across all samples, together with a regularization term:
\begin{equation}
\text{loss}=-\frac{1}{N}\sum_{n=1}^{N}\left\{ y_{n}\log \hat{P}_{\text{hit}}(n)+(1-y_{n})\log (1-\hat{P}_{\text{hit}}(n) \right\}+\beta\sum_{W}\Vert W \Vert^{2},
\end{equation}
where $\hat{P}_{\text{hit}}(n)$ is the inferred probability of hit for sample $n$, $\beta$ is the strength of the $\ell_2$ regularization, and $W$ represents all the effective parameters in the two excitatory and inhibitory filters.

The strength of the regularization $\beta$ was set to be $10^{-4}$, which was obtained by gradually increasing $\beta$ until the performance of the model on test data started to drop. The regularization sped up convergence of solutions, but the regularization strength did not strongly influence the main results in the paper.

To speed up training, rather than taking a temporal average as shown in \EQ{prob_model}, a snapshot was sampled randomly from each trajectory, and the probability of hit of this snapshot was used to represent the whole trajectory, i.e., $\hat{P}_{\text{hit}}=\sigma \left( \sum_{m}r_{m}(t)+b \right)$, where $t$ is a random sample from $\{1,2,\dots,T\}$. Mini-batch gradient descent was used in training, and the learning rate was 0.001.

After training, the models were tested on the entire trajectories with the probability of hit defined in \EQ{prob_model}. Models trained only on snapshots performed well on the test data. During testing, the performance of the model was evaluated by the area under the curve (AUC) of the receiver operating characteristic (ROC) and precision-recall (PR) curves \citep{hanley1982meaning,davis2006relationship}.
TensorFlow \citep{abadi2016tensorflow} was used to train all models.

\subsection{Clustering the solutions}
We used the following procedure to cluster the solutions. Each solution had an excitatory and an inhibitory filter. We flattened these two filters, and concatenated them into a single vector. (The elements at the corners were deleted since they are outside of the receptive field.) Thus, each solution was represented by a vector, from which we calculated the cosine distance for each pair of solutions. The obtained distance matrix was then fed into a hierarchical clustering algorithm \citep{2020SciPy-NMeth}. After obtaining the hierarchical clustering, the outward and inward filters were identified by their shape. We counted the non-zero filter elements corresponding to flow with components radiating outward and subtracted the number of non-zero filter elements corresponding to flow with components directed inward. If the resulted value was positive, the filters were labeled as outward; otherwise, the filters were labeled as inward. If the elements in the concatenated vector were all close to zero, then the corresponding filters were labeled as unstructured.

\subsection{Statistics}
To calculate the fraction of active units for the model with $M=256$ (\FIG{compareMultiUnits}B), we looked at the response curves of each unit to all trajectories of a specific type of stimuli, and if the unit response is above the baseline (dotted lines in \FIG{compareSinleUnits}B), then the unit is counted as active. So, for each trajectory/stimulus, we obtained the number of active units. After this, we calculated the mean and standard deviation across all the trajectories within each type of stimuli (Hit, Miss, Retreat, Rotation).

For a model with $M$ units, where $M \in \{1,2,4,8,16,32,64,128,192,256\}$, 200 random initializations were used to train it. Within these 200 training runs, the number of outward solutions $N_{\text{out}}$ were (starting from smaller values of $M$) 33, 44, 42, 46, 50, 49, 51, 50, 49, 46 (out of 150), and the number of inward solutions $N_{\text{in}}$ were 70, 67, 68, 67, 66, 64, 60, 33, 27, 12 (out of 150). The average score curves and dots in \FIG{outwardPrevail}A were obtained by taking the average among each type of solution, with the shading indicating two standard deviations. The curve and dots in \FIG{outwardPrevail}B are the ratio of the number of outward solutions to the number of inward solutions. To obtain error bars (grey shade), we considered the training results as a binomial distribution, with the probability of obtaining an outward solution being $N_{\text{out}}/(N_{\text{out}}+N_{\text{in}})$, and with the probability 
of obtaining an inward 
solution being $N_{\text{in}}/(N_{\text{out}}+N_{\text{in}})$. Thus, the standard deviation of this binomial distribution is $\sigma_{\text{b}}=\sqrt{N_{\text{out}}N_{\text{in}}/(N_{\text{out}}+N_{\text{in}})}$.  From this, we calculate the error bar as the propagated error \citep{caldwell2015propagation}:
\begin{equation}
\text{propagated error} = \frac{N_{\text{out}}}{N_{\text{in}}}\sqrt{\left(\frac{\sigma_{\text{b}}}{N_{\text{out}}}\right)^{2}+\left(\frac{\sigma_{\text{b}}}{N_{\text{in}}}\right)^{2}}.
\end{equation}

\section{Acknowledgments}

Research supported in part by NSF grants DMS-1513594, CCF-1839308, DMS-2015397, a  J.P.~Morgan Faculty Research Award, and the Kavli Foundation. We thank R. Tanaka, M. Agrochao, A. Gonzalez, G. Sager, W. Lei, T. Gou and other members in the Clark laboratory for valuable discussions and comments.

\bibliography{references}





\end{document}
