%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ELIFE ARTICLE TEMPLATE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PREAMBLE
\documentclass[pdftex,9pt,lineno]{elife}
% Use the onehalfspacing option for 1.5 line spacing
% Use the doublespacing option for 2.0 line spacing
% Please note that these options may affect formatting.
% Additionally, the use of the \newcommand function should be limited.

\usepackage{lipsum} % Required to insert dummy text
\usepackage[version=4]{mhchem}
\usepackage{siunitx}
\DeclareSIUnit\Molar{M}

\usepackage{amsmath}
\newcommand{\norm}[1]{\Vert {#1} \Vert}
\newcommand{\inprod}[2]{\ensuremath{\langle #1 , \, #2 \rangle}}
\newcommand{\mc}{\mathcal}
\newcommand{\mb}{\mathbb}
\newcommand{\emp}{\emptyset}
\newcommand{\sigmoid}{\text{sigmoid}}
\newcommand{\relu}{\text{\small\sc ReLU}}
\def\htheta{{\hat\theta}}
\def\k{{k}}
\def\d{{d}}
\def\reals{{\mathbb R}}
\def\({\left(}
\def\){\right)}
\def\[{\left[}
\def\]{\right]}
\def\bone{{\mathbf 1}}
\let\hat\widehat

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\trace}{tr}
\DeclareMathOperator*{\Var}{Var}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{A shallow neural network trained to detect collisions recovers features of visual loom-selective neurons}
% A shallow artificial neural network recovers properties of visual loom-selective neurons
% A simple network trained to detect collisions recovers features of visual loom-selective neurons
% Collision-detection inference, visual loom-selective neurons, shallow neural network (in abstract), simple neural network, collisions, impending collisions, Drosophila (in abstract), predicts, recovers, reproduces, *features, structure,

\author[1*]{Firstname Middlename Surname}
\author[1,2\authfn{1}\authfn{3}]{Firstname Middlename Familyname}
\author[2\authfn{1}\authfn{4}]{Firstname Initials Surname}
\author[2*]{Firstname Surname}
\affil[1]{Institution 1}
\affil[2]{Institution 2}

\corr{damon.clark@yale.edu}{DAC}
\corr{john.lafferty@yale.edu}{JDL}

\contrib[\authfn{1}]{These authors contributed equally to this work}
\contrib[\authfn{2}]{These authors also contributed equally to this work}

\presentadd[\authfn{3}]{Department, Institute, Country}
\presentadd[\authfn{4}]{Department, Institute, Country}
% \presentadd[\authfn{5}]{eLife Sciences editorial Office, eLife Sciences, Cambridge, United Kingdom}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE START
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
% Please provide an abstract of no more than 150 words. Your abstract should explain the main contributions of your article, and should not contain any material that is not included in the main text.
% Animals have evolved sophisticated visual circuits to detect looming objects. Studies of the visual system of \textit{Drosophila} have revealed that looming stimuli are selectively encoded by a suite of neurons, including LPLC2 neurons. In LPLC2 neurons, the dendrites are arranged in a distinctive anatomical structure and receive excitatory and inhibitory inputs that cause them to respond selectively to the radial expansion of the edges of a looming object. Our study aims to understand how the computations in LPLC2 neurons are related to the inference problem that the neuron appears to be solving: whether an object is looming towards teh fly. To do this, we trained anatomically-constrained shallow neural networks to detect whether or not a visual signal is an object on a collision course. We used these trained inference models ask how known properties of the biological neural circuits relate to the features of the artificial neural network trained on synthetic visual stimuli. We trained a single unit of our model on a set of diverse artificial visual stimuli to detect whether moving objects were on a collision course with the detector location. Surprisingly, the model arrived at two distinct solutions to this detection problem: one with dendritic weighting that mirrored LPLC2 and the other selective for inward-directed motion. We analyzed how each of these two solutions work to detect looming events. When we increased the number of units in the population, the performance of the model improved, and weighting similar to LPLC2 became more favored. When many units tiled visual space, the trained models also exhbited many of the response properties measured in LPLC2. Our findings suggests that LPLC2 can be understood as solving an inference problem, and that signals from the entire population of LPLC2 neurons are critical for understanding how LPLC2 reliably encodes looming stimuli.
In the visual system of \textit{Drosophila}, looming stimuli are selectively encoded by a suite of neurons, including LPLC2 neurons. The dendrites of the LPLC2 neurons are arranged in a distinctive structure that causes them to respond selectively to the outward expansion of the edges of a looming object. To understand the structure of this looming computation, we trained an anatomically-constrained shallow neural network to detect whether or not a visual signal corresponds to an object on a collision course. Surprisingly, the model arrived at two distinct solutions: one with dendritic weighting mirroring LPLC2 and the other selective for inward-directed motion. The LPLC2-mirroring solutions were favored when a population of model units was trained on the task. The trained models reproduced LPLC2 neuronâ€™s response patterns for a large range of stimuli, as well as canonical tuning measured in loom sensitive neurons, even though they were not trained on any neural data. These models show that LPLC2's properties and tuning are predicted by optimizing a neural network to detect looming events.
\end{abstract}


\section{Introduction}

\begin{figure}
\includegraphics[width=\linewidth]{figures/anatomy_paper.pdf}
\caption{Sketches of the anatomical structures of LPLC2 neurons. (A) An LPLC2 neuron has dendrites in lobula and the four layers of the lobula plate (LP): LP1, LP2, LP3 and LP4. (B) The schematics of the four branches of the LPLC2 dendrites in the four layers of the LP. The arrows indicate the cardinal directions of the corresponding LP layers, which receive motion signals from motion detection neurons. (C) The outward dendritic structure of an LPLC2 neuron coincides with the expanding edges of a looming object (black circle). (D) A population of LPLC2 neurons (over 200) converge their axons to the GF, a descending neuron, to contribute to escaping behaviors.}
\label{fig:anatomy}
\end{figure}

For animals living in dynamic visual environments, it is important to detect the approach of predators or other dangerous objects. Many species, from insects to humans, rely on a range of visual cues to identify approaching, or looming, objects \citep{regan1978looming,sun1998computation,gabbiani1999computation,card2008visually,munch2009approach,temizer2015visual}. Among other cues, looming objects create characteristic visual flow fields. When an object is on a ballistic collision course with an animal, its edges will appear to the observer to expand radially outward, gradually occupying a larger and larger portion of the visual field. An object heading towards the animal, but which will not collide with it, also expands to occupy an increasing portion of the visual field, but its edges do not expand radially outwards with respect to the observer. Instead, they expand with respect to the object's center so that opposite edges are perceived to be moving in the same direction (Fig. (\ref{fig:stimuli_flow})). A collision detector must distinguish between these two cases, while also avoiding predicting collisions in response to myriad other visual flow fields created by the animal's own motion. Thus, loom detection can be framed as a visual inference problem.

Many sighted animals solve this inference problem with high precision, thanks to robust loom-selective neural circuits evolved over hundreds of millions of years. The neuronal mechanisms for response to looming stimuli have been studied in a wide range of vertebrates, from cats and mice to zebrafish, as well as in humans
\citep{king1992use,hervais2015looming,ball1971infant,liu2011neuronal,salay2018midline,liu2011neuronal,shang2015parvalbumin,wu2005tectal,temizer2015visual,dunn2016neural,bhattacharyya2017visual}.
In invertebrates, more detailed anatomical, neurophysiological, behavioral and modeling studies have investigated loom detection, especially for locusts and flies \citep{oliva2014computation,sato2014role,santer2005gliding,rind1996neural,card2008visually,de2012loom,muijres2014flies,klapoetke2017ultra,von2017feature,ache2019neural}.
An influential mathematical model of loom detection was derived by studying the responses of the giant descending neurons of locusts, which established a relationship between the timing of the neurons' peak responses and an angular size threshold for the looming object \citep{gabbiani1999computation}. Similar models have been applied to analyze looming signals in  flies, where  genetic tools make it possible to precisely dissect neural circuits, revealing various neuron types that are sensitive to looming signals \citep{von2017feature,ache2019neural,morimoto2020spatial}.

The starting point for our computational model of loom detection is the known neuroanatomy of the compound eye of the fly. In particular, the loom-sensitive neuron LPLC2 (lobula plate/lobula columnar, type 2) \citep{wu2016visual} has been studied in detail. These neurons tile visual space, sending their axons to a descending neuron called the giant fiber (GF), which triggers  the fly's jumping and takeoff behaviors \citep{card2008visually,von2017feature,ache2019neural}. Each LPLC2 neuron has four dendritic branches that receive inputs from the four layers of the lobula plate (LP) (Fig. \ref{fig:anatomy}A) \citep{maisak2013directional,klapoetke2017ultra}. The retinotopic LP layers host the axon terminals of motion detection neurons, and each layer uniquely receives motion information in one of the four cardinal directions \citep{maisak2013directional}. Moreover, the physical extensions of the LPLC2 dendrites align with the preferred motion directions in the corresponding LP layers (Fig. \ref{fig:anatomy}B) \citep{klapoetke2017ultra}. These dendrites form an outward radial structure, which matches the moving edges of a looming object that expands in the visual field (Fig. \ref{fig:anatomy}C). Common stimuli such as the wide-field motion generated by movement of the insect only match part of the radial structure, and strong inhibition for inward-directed motion suppresses responses to such stimuli. Thus, the structure of the LPLC2 dendrites favors responses to objects with edges moving radially outwards, corresponding to motion toward center of the receptive field.

The focus of this paper is an investigation into how loom detection in LPLC2 can be seen as the solution to a computational inference problem. Can the structure of the LPLC2 neurons be explained in terms of optimization---carried out during the course of evolution---for the task of predicting which trajectories will result in collisions?
How does coordination among the population of more than 200 LPLC2 neurons tiling a fly's visual system effect this optimization?  To answer these questions, we built a simple anatomically-constrained loom detector, which receives positive and negative inputs from motion signals in the four cardinal directions. We trained the model on artificial stimuli, with the objective of detecting visual objects on a collision course with the observer. Surprisingly, we find that optimization finds two distinct types of solutions, with one resembling the LPLC2 neurons and another having a very different configuration. We analyze how each of these solutions detects looming events and where they show distinct individual and population behaviors.
When the number of units tiling visual space is increased, the solutions that resemble the actual LPLC2 neurons perform better and become favored. When tested on visual stimuli not in the training data, the optimized solutions exhibit response curves that are similar to those of actual LPLC2 neurons as measured by \cite{klapoetke2017ultra}. Importantly, the optimized model reproduces the canonical linear relationship between the peak time relative to collision and the size-to-speed ratio. It also shows characteristics of an angular size encoder, despite its direction-selective motion inputs, which is consistent with experiments \citep{gabbiani1999computation,von2017feature,ache2019neural}.

\section{Results}

\subsection{A set of artificial visual stimuli is designed for training models}

Our goal is to compare computational models trained to perform loom-detection with the biological computations in LPLC2. We first created a set of stimuli to act as training data for the inference task. We considered the following four types of motion stimuli: loom-and-hit (abbreviated as hit), loom-and-miss (miss), retreat, and rotation (Fig. \ref{fig:stimuli_traj}). The hit stimuli consist of a sphere that moves ballistically towards the origin on a collision course. The miss stimuli consist of a sphere that moves ballistically towards the origin but misses it. The retreat stimuli consist of a sphere moving ballistically away from the origin. The rotation stimuli consist of objects rotating about an axis. All stimuli were designed to be isotropic; the first three stimuli could have any orientation in space, while the rotation could be about any axis. All trajectories were simulated in the frame of reference of the fly at the origin, with distances measured with respect to the origin. For simplicity, the fly is assumed to be a point particle with no volume (Red dots in Fig. \ref{fig:stimuli_traj} and the apexes of the cones in Fig. \ref{fig:stimuli_flow}). For hit, miss, and retreat stimuli, the spherical object has unit radius, and for the case of rotation, there were 100 objects of various radii scattered isotropically around the fly (Fig. \ref{fig:stimuli_flow}).

\begin{figure}
\includegraphics[width=\linewidth]{figures/stimuli_1_paper.pdf}
\caption{Four types of synthetic stimuli. (A) Orange lines represent trajectories of the stimuli. The black dots represent the starting points of the trajectories. For hit, miss, and retreat cases, multiple trajectories are shown. For rotation, only one trajectory is shown. (B) Distances of the objects to the fly eye as a function of time step.}
\label{fig:stimuli_traj}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
% \figsupp[Shorter caption for main text.]{This is a supplementary figure's full caption, which will be used at the end of the manuscript.}{\includegraphics[width=6cm]{frog}}\label{figsupp:sf1}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{figures/stimuli_2_paper.pdf}
\caption{Corresponding to Fig. \ref{fig:stimuli_traj}), snapshots of optical flows and flow fields calculated by a Hassenstein Reichardt correlator (HRC) model. First row: 3d rendering of the spherical objects and the LPLC2 receptive field (the cones) at a specific time step. The orange arrows indicate the moving directions of the objects. Second row: 2d projections of the objects (black shades) within the LPLC2 receptive field (the grey circles). Third row: the thin black arrows indicate flow fields generated by the edges of the moving objects. Forth to seventh rows: decomposition of the flow fields in the four cardinal directions with respect to the LPLC2 neuron under consideration: downward, upward, rightward, and leftward, as indicated by the thick black arrows.}
\label{fig:stimuli_flow}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[Tuning curve of HRC motion estimator and distributions of HRC outputs.]{(A) [THE PEAK SHOULD BE AROUND 150-200, AND NEED TO DOUBLE CHECK.] Tuning curve (red) of the HRC motion estimator. Grey shade indicates the velocity range used in simulations. (B) The distributions of all the HRC outputs for different types of stimuli.}{\includegraphics[width=\linewidth]{sup_figures/stimuli_2_sup_paper.pdf}}\label{figsupp:sf1_stimuli_flow}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}


\subsection{An anatomically-constrained mathematical model detects loom}

We designed and trained a simple, anatomically-constrained neural network (Fig. \ref{fig:model}) to infer whether or not a moving object will collide with the fly. The features of this network are designed to mirror anatomical features of the fly's LPLC2 neurons; see Fig~\ref{fig:anatomy}.

Model units receive input from a 60 degree diameter cone of visual space, represented by white cones and grey circles in Fig. \ref{fig:stimuli_flow}, mirroring the receptive field size that has been measured for LPLC2 \citep{klapoetke2017ultra}. The four stimulus sets were projected into this receptive field for training and evaluating the model.

The inputs to the model are local directional signals computed in the four cardinal directions at each point of visual space: downward , upward, rightward, and leftward (Fig. \ref{fig:stimuli_flow}). These represent the motion signals from T4 and T5 neurons in the four layers of the lobula plate \citep{maisak2013directional}. They are computed as the non-negative components of a Hassenstein-Reichardt correlator model \citep{hassenstein1956systemtheoretische} in both horizontal and vertical directions, which acts on the intensities of the projected stimuli (see Methods). The motion signals are computed with a spacing of 5 degrees, roughly matching the spacing of the ommatidia and processing columns in the fly eye \citep{stavenga2003angular}.

Each model unit can weight the motion signals from the four layers using linear spatial filters. There are two sets of non-negative filters, the excitatory filters and the inhibitory filters; these are shown in red and blue, respectively, in Fig. \ref{fig:model}A. Each set of filters has four components, or branches, integrating motion signals from the four cardinal directions, respectively. These spatial filters represent excitatory inputs to LPLC2 directly from T4 and T5 in the lobula plate, and inhibitory inputs  mediated by local interneurons \citep{klapoetke2017ultra,mauss2015neural}. All eight filters act on the 60 degree receptive field of an unit. A 90-degree rotational symmetry is imposed on the filters, so that the filters in each layer are identical. Moreover, each filter is symmetric about the axis of motion (see Methods). No further assumptions are made about the structure of the filters.

The model incorporates a fundamental difference between the excitatory and inhibitory branches: while the integrated signals from each excitatory branch are sent directly to the downstream computations, the integrated signals from each inhibitory branch are rectified before being sent downstream. This difference reflects anatomical constraints of the inputs to an actual LPLC2 neuron, where the excitatory inputs are direct connections with LPLC2 while the inhibitory inputs are mediated by inhibitory interneurons (LPi) between LP layers \citep{mauss2015neural,klapoetke2017ultra}. The outputs of the eight branches are summed and rectified to generate the output of a single model unit in response to a given stimulus; see Fig. \ref{fig:model}A.

In the fly eye, a population of LPLC2 neurons converges onto the GF (Fig. \ref{fig:anatomy}D). Accordingly, in our model there are $M$ replicates of each model unit, with orientations that are spread uniformly over the $4\pi$ steradians of the unit sphere (see Methods). In this way, the receptive fields of the $M$ units roughly  tile the whole angular space, with or without overlap, depending on the value of $M$. The sum of the responses of the $M$ model units is fed into a sigmoidal function to generate the probability of a collision for a given trajectory.

\begin{figure}
\includegraphics[width=\linewidth]{figures/model_sketch_paper.pdf}
\caption{Schematic of the model. (A) Single unit. There are two sets of nonnegative filters: excitatory (red) and inhibitory (blue). Each sets of filters have four branches, and each branch receives motion signals (forth to seventh rows in Fig. \ref{fig:stimuli_flow}) from the corresponding layer of the LP. The integrated signals from the excitatory branches and the inhibitory branches (rectified) are pooled together to go through a rectifier to produce an output, which is the response of a single unit. Each inhibitory input goes through a rectifier before pooled. (B) The outputs from $M$ units are summed and fed into a sigmoid function to estimate the probability of hit. (C) The $M$ units have their orientations almost evenly distributed in the angular space. Red dots and lines represent the centers of the receptive fields and the grey lines represent the boundaries of the receptive fields.}
\label{fig:model}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[Coordinate system.]{[NEED TO USE 3D CONE ARROWS] The frame of reference $\Sigma$ is fixed on the fly head. The frame of references $\Sigma_{m}\ (m = 1, 2, \dots, M)$ are associated with each local loom detector, the center of which is represented by a red dot. For $\Sigma_{m}$, only $x_{m}$ and $z_{m}$ are shown, and $y_{m}$ axis should be chosen such that $\Sigma_{m}$ is right-handed.}{\includegraphics[width=\linewidth]{sup_figures/coordinates_sup_paper.pdf}}\label{figsupp:sf1}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}


\subsection{Optimization finds two distinct solutions to the loom-inference problem}

The objective of this study is to investigate how the binary classification task shapes the excitatory and inhibitory filters, including how the number of units $M$ affects the results. We begin with the simplest model, which possess only a single unit, i.e., $M=1$. The task for this simple model is to distinguish hits from other types of stimuli in our artificial stimulus set (Fig. \ref{fig:stimuli_traj}, Fig. \ref{fig:stimuli_flow}).

After initializing the training with 200 different random filters, we find that the converged solutions fall into three broad categories (Fig. \ref{fig:trained_res_singlecell}A, B). One set of solutions is largely unstructured (labeled in black); we will ignore these for the rest of the analysis. The two structured solutions are interesting because, surprisingly, they have  spatial structures that are roughly opposite from one another (magenta and green). Based on the configurations of the excitatory filters (METHOD), we call one solution type \textit{outward filters}   (magenta), and we called the other type \textit{inward filters} (green) (see Fig. \ref{fig:trained_res_singlecell}C and Fig. \ref{figsupp:sf1_trained_res_singlecell}A). In this single-unit model, the inward solutions perform better than the outward solutions on the discrimination task (Fig. \ref{fig:trained_res_singlecell}D) and Fig. \ref{figsupp:sf1_trained_res_singlecell}B).

As the number of units $M$ increases, the population of cells covers a larger angular space, and when $M$ is large enough (approximately $M=X$), the receptive fields of the units begin to overlap with each other (Fig. \ref{fig:trained_res_multicells}A). In the fly visual system there are over 200 LPLC2 neurons across both eyes \citep{ache2019neural}, which corresponds to a very dense distribution of the units. This is illustrated by the third row in Fig. \ref{fig:trained_res_multicells}A) where $M=256$. When $M$ is large, approaching objects from any direction are detectable and in fact, such objects signal can be detected simultaneously by many neighboring units. Interestingly, the two oppositely structured solutions persist, regardless of the value of $M$ (Figures \ref{fig:trained_res_multicells},  \ref{figsupp:sf1_trained_res_multicells}, \ref{figsupp:sf2_trained_res_multicells},  \ref{figsupp:sf3_trained_res_multicells}). In some outward solutions, structures on the right side of the inhibitory filters are similar to structures of the corresponding excitatory filters. This indicates a degree of redundancy, or non-identifiability in the model (Fig. \ref{figsupp:sf2_trained_res_multicells}, Fig. \ref{figsupp:sf3_trained_res_multicells}).

Cells with outward-oriented filters are activated by motion radiating outwards from the center of the receptive field. Thus, these excitatory filters resemble the dendritic structures of the actual LPLC2 neurons observed in experiments, where for example, the rightward motion sensitive branch (LP2) occupies mainly the right side of the receptive field. In the outward solutions, the rightward motion-sensitive inhibitory filter mainly occupies the \textit{left} side of the receptive field. This is also consistent with the properties of the lobula plate intrinsic (LPi) interneurons, which project inhibitory signals roughly retinotopically from one LP layer to an adjacent layer with opposite directional tuning \citep{mauss2015neural,klapoetke2017ultra}.

The unexpected inward-oriented filters have the opposite structure. In the inward solutions, the rightward sensitive excitatory filter occupies the left side of the receptive field, and the inhibitory filter occupies the right side. Such weightings make the model selective for motion converging towards the receptive field center. At first glance, this is a puzzling structure for a loom detector, so we explored the response properties of the inward and outward solutions in more detail.

\begin{figure}
\includegraphics[width=\linewidth]{figures/trained_results_Q1_paper.pdf}
\caption{Two distinct types of models appear from training a single unit on the binary classification task. (A) Clustering of the trained filters/weights shown as a dengrogram. Different colors indicate different clusters, which are preserved for the rest of the paper. (B) The trajectories of the loss functions during training. (C) The two distinct types of models are represented by two types of filters that are exactly the opposite to each other: outward model (magenta) and inward model (green). The excitatory filters are shown as red, and the inhibitory filters are shown as blue. (D) Performances of the two models. TPR: true positive rate; FPR: false positive rate; ROC: receiver operating characteristic; PR: precision recall; AUC: area under the curve.}
\label{fig:trained_res_singlecell}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[More examples of the trained filters for the two types of models and the inferred probability of hit for the four types synthetic stimuli.]{(A) Trained filters: outward model (magenta) and inward model (green). (B) Probability of hit inferred by a single unit for the four types synthetic stimuli.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_Q1_sup_paper.pdf}}\label{figsupp:sf1_trained_res_singlecell}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{figures/trained_results_multicells_paper.pdf}
\caption{The outward and inward models also appear for models with multiple units. (A) Left column: angular distributions of the units, where red dots are centers of the receptive fields, the grey circles are the boundaries of the receptive field and the black star shows the top of the fly head. Middle column: 2d mapping of the units with symbols being the same as in the left column. Right column: clustering results shown as dendrogams with color codes the same as in Fig. \ref{fig:trained_res_singlecell}A). (B) Examples of the trained excitatory/inhibitory filters for outward and inward models with different numbers of units.}
\label{fig:trained_res_multicells}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[Performance of the models.]{Same as in Fig. \ref{fig:trained_res_singlecell}D) but for models with multiple units.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_multicells_sup1_paper.pdf}}\label{figsupp:sf1_trained_res_multicells}
\figsupp[More examples of the outward filters.]{Outward filters for models with different units.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_multicells_sup2_paper.pdf}}\label{figsupp:sf2_trained_res_multicells}
\figsupp[More examples of the inward filters.]{Inward filters for models with different units.}{\includegraphics[width=\linewidth]{sup_figures/trained_results_multicells_sup3_paper.pdf}}\label{figsupp:sf3_trained_res_multicells}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}


\subsection{Outward and inward filters are selective to signals in different ranges of angles}

To understand the difference between the two types of solutions and why the inward filters can predict collisions, we investigated how they respond to hit stimuli from different incoming angles $\theta$ (Fig. \ref{fig:compare_single}A). When there is no signal, the baseline activity of outward units is zero; however, the baseline activity of inward units is above zero (grey dashed lines in Fig. \ref{fig:compare_single}B, C). This is because the trained intercepts are negative in the outward case, but positive in the inward case (see Methods). Second, as shown in Fig. \ref{fig:compare_single}B,C, the outward filters respond strongly to stimuli near the center of the receptive field, but do not respond to stimuli having angles larger than $\theta \tilde 30^{\circ}$. In contrast, units with inward filters respond negatively to looming stimuli approaching toward the center and positively to stimuli approaching from the periphery of the receptive field, with angles between $\tilde 30^{\circ}$ and $\tilde 90^{\circ}$ (Fig. \ref{fig:compare_single}B, C). This helps explain why the inward units can act as loom detectors: they are sensitive to hit stimuli originating in a larger solid angle. The hit signals are isotropic, as shown in Fig. \ref{fig:stimuli_traj}A, so the number of stimuli within angles $30^{\circ}$ and $90^{\circ}$ is much larger than the number of stimuli with angles below $30^{\circ}$ (Fig. \ref{fig:compare_single}D). Thus, the inward solutions is sensitive to more hit cases than the outward solutions. One may visualize these responses as heat maps of the mean response of the models in terms of object distance to the fly and the incoming angle (Fig. \ref{fig:compare_single}E). For the hit cases, the response patterns are consistent with the intuition about trajecotry angles (Fig. \ref{fig:compare_single}C). As expected, the inward solutions respond to the retreating signals with angles near $180^{\circ}$, since the motion of edges in that case is radially inward.

\begin{figure}
\includegraphics[width=\linewidth]{figures/compare_outward_inward_single_unit_paper.pdf}
\caption{The outward and inward filters show distinct behaviors: single unit analysis. (A) Trajectories of hit stimuli with different incoming angles $\theta$. Symbols are the same as in Fig. \ref{fig:stimuli_traj}) except that the upward red arrow represents the orientation of one unit. The numbers with degree unit indicate the specific values of the incoming angles. (B) Response patterns of a single unit with either outward (magenta) or inward (green) filters obtained from models with 32 and 256 units, respectively. The grey dashed lines show the baseline activity of the unit when there is no stimulus. The solid grey concentric circles correspond to the values of the incoming angles in (A). (C) Temporally averaged responses against the incoming angle $\theta$. Symbols and color codes are the same as in (B). (D) Histogram of the incoming angles for the hit stimuli in Fig. \ref{fig:stimuli_traj}A). The grey curve represents a rescaled sine wave with half of the period. (E) Heatmaps of the responses of a single unit against the incoming angle $\theta$ and the distance to the fly head, for both outward and inward filters obtained from models with 32 and 256 units, respectively. A square root was taken on the responses.}
\label{fig:compare_single}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
% \figsupp[Shorter caption for main text.]{This is a supplementary figure's full caption, which will be used at the end of the manuscript.}{\includegraphics[width=6cm]{frog}}\label{figsupp:sf1}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}

\subsection{Outward solutions have sparse codings}

Individual units of the two models are very different from each other in their filter structure and response patterns to different stimuli. We decided to investigate how these differences manifest in the activities of populations of units, when units are trained to collectively predict the probability of hit. In populations of units, the outward and inward units exhibit very different response patterns for a given hit stimulus (\ref{fig:compare_multi}A, B). In particular, active outward units usually respond more strongly than inward units, but more inward units will be activated. This is consistent with the findings above, in which inward filter shapes responded to hits arriving from a wider distribution of angles. The retreat signals actually triggered more active units than the hit signals for the outward solutions, which is because the retreat signals swept through more partial dendritic structures and caused more low level activity (Fig. \ref{figsupp:sf2_compare_multi}).

When a population of units encodes stimuli, at each time point, the sum of the activities of the units is used to infer the probability of hit. In our trained models, the outward and inward models give similar probabilities of hit (\ref{fig:compare_multi}A). Both types of models can give accurate inferences for the different stimuli (Fig. \ref{fig:compare_multi}C). In some cases, misses can be very similar to hits if the object passes near the origin. The models reflect this in their responses to near misses which have higher hit probabilities than far misses (Fig. \ref{fig:compare_multi}D).

\begin{figure}
\begin{fullwidth}
\includegraphics[width=\linewidth]{figures/compare_outward_inward_multiple_units_paper.pdf}
\caption{Population coding. (A) Top row: a snapshot of the responses of the outward units (magenta dots) for a hitting object (grey shade). Symbols and color codes are the same as in Fig. \ref{fig:trained_res_multicells}A). Middle row: the whole trajectories of the responses for the same hitting object as in the top row. Bottom row: the whole trajectories of the probability of hit for the same hitting object as in the top row. (B) Fractions of the units that are activated by different types of stimuli (Hit, Miss, Retreat, Rotation) as a function of numbers of units $M$ in the models. The lines represent the mean values averaged across samples, and the shaded areas show one standard deviation. Magenta: outward; green: inward. (C) Histograms of the probability of hit inferred by models with 32 or 256 units for the four types of synthetic stimuli. (D) The inferred probability of hit as a function of the minimum distance of the object to the fly eye for the miss cases.}
\label{fig:compare_multi}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[The same as (A), but for miss and retreat stimuli.]{(A) An example of a miss stimulus. (B) An example of a retreat stimulus.}{\includegraphics[width=\linewidth]{sup_figures/compare_outward_inward_multiple_units_sup_paper.pdf}}\label{figsupp:sf1_compare_multi}
\figsupp[Sample response curves.]{(A) Sample response curves of the active units in the outward model with $M=256$. (B) The same as (A), but for inward model.}{\includegraphics[width=\linewidth]{sup_figures/compare_outward_inward_multiple_units_sup2_paper.pdf}}\label{figsupp:sf2_compare_multi}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{fullwidth}
\end{figure}


\subsection{Large populations of units improve performance and favor outward filters}

Since a larger number of units will cover an increasing spatial area of the visual field, the population of units can in principle provide more information about the incoming signals. In general, the models perform better as the number of units $M$ increases (Fig. \ref{fig:outward_prevail}A). When $M$ is above 32, both the ROC-AUC and PR-AUC scores are almost 1 (see Methods), which indicates that the model is very accurate on the binary classification task presented by the four types of synthetic stimuli.

We wanted to investigate whether there were differences between the inward and outward filters that might have favored the outward solution in the biological circuit. To do this, we calculated the ratio of the number of outward filters to inward filters that arise out of 200 random initializations in models with $M$ units, as we swept $M$. Interestingly, as the number of units increased, an increasing proportion of solutions had outward filters (Fig. \ref{fig:outward_prevail}B). For models with 256 units, the chance that an outward filter appears as a solution is almost four times larger than when $M=1$. Indeed, although both outward and inward models with large $M$ have similar ROC-AUC and PR-AUC scores,  the outward filters have lower cross entropy loss for large populations of units (Fig. \ref{fig:outward_prevail}C). These results suggest that when there are many units, optimization favors the outward solution, both in terms of performance and in the likelihood of finding a specific solution.

\begin{figure}
\includegraphics[width=\linewidth]{figures/outward_better_than_inward_paper.pdf}
\caption{Large populations of units improve performances and favor outward models. (A) Both ROC and PR AUC scores increase as the number of units increases. Lines and dots: average scores; shades: one standard deviation of the scores. Magenta: outward models; green: inward models. (B) The black line and dots show the ratio of the numbers of the two types of the models obtained by varying randomly the initial conditions of the training. The grey shades indicate one standard deviation obtained by assuming the training is a binomial event. The dotted horizontal line indicates the ratio of 1. (C) AS the population of units increase, cross entropy losses of the outward models become lower than the inward models.}
\label{fig:outward_prevail}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[Same as in (A) and (B) but for training in different conditions.]{(A) A different probability model (METHOD). (B) Training without rotation stimuli. (C) Training with larger distances of the objects to the fly eye.}{\includegraphics[width=\linewidth]{sup_figures/outward_better_than_inward_sup_paper.pdf}}\label{figsupp:sf1_outward_prevail}
% \figsupp{This is another supplementary figure.}{\includegraphics[width=6cm]{frog}}
% \videosupp{This is a description of a video supplement.}\label{videosupp:sv1}
% \figdata{This is a description of a data source.}\label{figdata:first}
% \figdata{This is another description of a data source.}\label{figdata:second}
\end{figure}

\subsection{Activation patterns of computational solutions resemble biological responses}

The outward models have a receptive field structure that is similar to LPLC2 neurons, based on their anatomy and functional studies. However, it is not clear whether these models possess the functional properties of LPLC2 neurons, which have been studied systematically \cite{klapoetke2017ultra,von2017feature,ache2019neural}. To see how trained units compare to LPLC2 neuron properties, we presented stimuli to the trained model (\ref{fig:replication}A) to compare its responses to those measured in LPLC2 to similar stimuli.

The model behaves similarly to LPLC2 neurons on many different types of stimuli. Not surprisingly, the model is selective to loom signals and does not have strong responses to non-looming signals (Fig. \ref{fig:replication}B). Moreover, the model closely follows the response of LPLC2 neurons to various expanding bar stimuli, including the inhibitory effects of inward motion (Fig. \ref{fig:replication}C, D). In addition, in experiments, motion signals that appear at the periphery of the receptive field suppress the activity of the LPLC2 neurons (periphery inhibition) \citep{klapoetke2017ultra}, and this phenomenon is successfully predicted by the model (Fig. \ref{fig:replication}E, F) due to the broad inhibitory filters that the model learns (Fig. \ref{fig:replication}A). Interestingly, the model also correctly predicts response patterns of the LPLC2 neurons for expanding bars with different orientations (Fig. \ref{fig:replication}G, H). 

The ratio of object size to approach velocity, or $R/v$, is an important parameter for looming stimuli, and many studies have investigated how the response patterns of loom-sensitive neurons depend on this ratio (Top panels in Fig. \ref{fig:replication}I, J, K, L) \citep{gabbiani1999computation,von2017feature,ache2019neural}. Here, we presented the trained model (\ref{fig:replication}A) with hit stimuli with different $R/v$ ratios, and compared its behaviors with the experimental data (Fig. (\ref{fig:replication}I-L)). Surprisingly, although our model only has the angular velocities as the inputs (Fig. (\ref{fig:stimuli_flow})), it reliably encodes the angular sizes rather than the angular velocities, indicated by the collapsed response curves (up to different scales) when plotted against the angular sizes (Fig. \ref{fig:replication}J) \citep{von2017feature}. One the contrary, for angular velocities, the response curves shift for different $R/v$ ratios, which means they depend on the velocities $v$ of the object ($R$ is fixed to be 1.). Both of these response properties are consistent with properties of LPLC2. Meanwhile, a canonical linear relationship between the peak response time relative to the collision and the $R/v$ ratio was also reproduced by the optimized model (Fig. \ref{fig:replication}L) \citep{gabbiani1999computation,ache2019neural}. The sudden jump of the last two points in the middle panel is caused by some discrepancies of the summed responses (rightmost two gray curves in the middle panel of Fig. \ref{fig:replication}I)]. 

Importantly, a different outward solution from the same training procedure could reproduce many of the same effects (Fig. \ref{figsupp:sf1_replication}), but it predicts the patterns in the wide expanding bars differently and out of phase from the biological data (Fig. \ref{figsupp:sf1_replication}H). This different solution also does a poor job predicting the response curves of the LPLC2 neurons to looming signals with different $R/v$ ratios, although the collapsed and shifted features remain when plotted as functions of angular size and velocity (Fig. \ref{figsupp:sf1_replication}J, K). This shows that even within the family of learned outward models, there is variability in the learned response properties. Though solving the inference problem obtains many of the response properties, additional constraints would be required to more precisely reproduce the LPLC2 responses.

\begin{figure}
\begin{fullwidth}
\includegraphics[width=\linewidth]{figures/replication_paper.pdf}
\caption{Models trained on binary classification tasks exhibited similar responses to LPLC2 neurons observed in experiments. (A) Excitatory and inhibitory filters of the outward model with 256 units. (B-H) Comparisons of the responses of the model in (A) and LPLC2 neurons. Black lines: data \citep{klapoetke2017ultra}; magenta lines: model. Compared with the ones in the paper \citep{klapoetke2017ultra}, all the stimuli gadgets here except the ones in (B) have been rotated 45 degrees to the frame of reference that is attached to the fly head to match the cardinal directions of the LPLc2 neurons/units. (I) Top: temporal trajectories of the angular sizes for different $R/v$ ratios (Green, 10 msec; light green, 20 msec; orange, 40 msec; red, 80 msec; gray scales, 100 msec, 120 msec, 140 msec, 160 msec, 180 msec, 200 msec. This color code applies to (I-L).). Middle: responses as functions of time steps for the sum of all the 256 units. Bottom: responses as functions of time steps for one of the 256 units. (J-L) Responses as functions of angular sizes (J), response as functions of angular velocities (K), linear relationships between peak time relative to collision and $R/v$ ratios (L). Top: experimental data (LPLC2/non-LC4 components of GF activities. Reproduced from \citep{von2017feature,ache2019neural}). Middle: sum of all the 256 units. Bottom: one of the 256 units.}
\label{fig:replication}
%% If the optional argument in the square brackets is "none", then the caption *will not appear in the main figure at all* and only the full caption will appear under the supplementary figure at the end of the manuscript.
\figsupp[Same as in the main figure but for a different outward model obtained from the same training procedure.]{}{\includegraphics[width=\linewidth]{sup_figures/replication_sup1_paper.pdf}}\label{figsupp:sf1_replication}
\end{fullwidth}
\end{figure}


\section{Discussion}

The radially structured dendrites of the LPLC2 neuron in the lobula plate can account for its response to motion radiating outward from the receptive field center \citep{klapoetke2017ultra}. Our results show that the logic of this computation can be understood in terms of inferential loom detection by the \textit{population} of units. In particular, for an individual detector unit, an inward structure makes a better loom detector than an outward structure, since it is sensitive to looming objects originating from a wider array of incoming angles (Figure \ref{fig:compare_single}). As the number of units across visual space increases, the outward-sensitive receptive field structure is represented more often in the optimal solution. The solution depends on the number of detectors because the receptive fields increasingly overlap as the population grows (Fig \ref{fig:trained_res_multicells}). This result is consistent with prior work showing that populations of neurons often exhibits different and improved coding strategies compared to individual neurons \citep{pasupathy2002population,georgopoulos1986neuronal,vogels1990population,franke2016structures,zylberberg2016direction,cafaro2020global}. Thus, understanding anatomical, physiological, and algorithmic properties of individual neurons can require considering the population response. The solutions we found to the loom inference problem suggest that individual LPLC2 responses should be interpreted in light of the population of LPLC2 responses.

Surprisingly, the trained outward model clearly exhibits the properties of an angular size encoder (Fig. \ref{fig:replication}I-L), even though the inputs to the model are a field of motion signals. There are two ways that this is made possible. First, in a looming stimulus, the angular size and angular velocity are correlated \citep{gabbiani1999computation}, which means the angular size affects the magnitude of the motion signals. Second, the angular size is proportional to integrated length of the outward-moving edges of looming objects. The angular circumference of the looming stimulus determines how many motion detector are activated, so that motion signal strength is related to size. Both of these effects influence the response patterns of the model units and the LPLC2 neurons. Our results shed lights on the discussions of $\eta$-like (encoding angular size) and $\rho$-like (encoding angular velocity) looming sensitive neurons in the literature \citep{gabbiani1999computation,wu2005tectal,liu2011neuronal,shang2015parvalbumin,temizer2015visual,dunn2016neural,von2017feature,ache2019neural}. In particular, these optimized models clarify an interesting but puzzling fact: LPLC2 neurons transform their inputs of direction-selective motion signals to computations of angular size \citep{ache2019neural}. Consistently, our model shows the linear relationship between the peak time relative to collision and the $R/v$ ratio, which looming sensitive neurons that encode angular size should follow \citep{peek2016comparative}. In both cases, these properties appear to be the simple result of training the constrained model to reliably detect looming stimuli.

The units of the outward model exhibit sparsity in their responses to looming stimuli, in contrast to the denser representations in the inward model (Fig. (\ref{fig:compare_multi})). During a looming event, most of the units are quiet and only a few adjacent units have very large activities, reminiscent of sparse codes that seem to be favored, for instance, in cortical encoding of visual scenes \citep{olshausen1996emergence,olshausen1997sparse}. Since the readout of our model is a summation of the activities of the units, sparsity does not directly affect the performance of the model, but is an attribute of the favored solution. For a model with a different loss function or noise, the degree sparsity might be crucial. For instance, the sparse code of the outward model might make it easier to localize the loom stimulus \citep{morimoto2020spatial}, or might make the population response more robust to noise \citep{field1994goal}. 

Experiments have shown that inhibitory circuits play an important role for the selectivity of LPLC2 neurons. For example, motion signals at the periphery of the receptive field of an LPLC2 neuron inhibit its activity; such peripheral inhibition causes various interesting response patterns of the LPLC2 neurons to different types of stimuli \citep{klapoetke2017ultra}. However, the structure of this inhibitory field is not fully understood, and our model provides a tool to investigate how the inhibitory inputs to LPLC2 neurons affect circuit performance on loom detection tasks. Specifically, strong inhibition on the periphery of the receptive field arises naturally in the outward solutions after optimization \citep{klapoetke2017ultra}. The broad inhibition appears in our model to suppress responses to the non-hit stimuli. As in the data, the inhibition is broader than one might expect if the neuron were simply being inhibited by inward motion.

The synthetic stimuli used to train models in this study were unnatural in two ways. The first way was in the proportion of hits and non-hits. We trained with 25\% of the training data representing hits. The true fraction of hits among all stimuli encountered by a fly is undoubtedly much less, and this affects how the loss function weights different types of errors. It is also clear that a false-positive hit (in which a fly might jump to escape an object not on collision course) is much less penalized during evolution than a false-negative (in which a fly doesn't jump and an object collides, presumably to the detriment of the fly). It remains unclear how to choose these weights in the training data or in the loss function, but they affect the receptive field weights optimized by the model.

The second issue with the stimuli is that they were caricatures of stimulus types, but did not incorporate the richness of natural stimuli. This richness could include natural textures and spatial statistics \citep{ruderman1994statistics}. This richness could also include more natural trajectories for approaching objects. Another way to enrich the stimuli would be to add noise, either in inputs to the model or in the model's units themselves. These aspects of the stimuli were all neglected in this initial study, in part because it is difficult to find characterizations of natural loom events. An interesting future direction will be to investigate the effects of more complex and naturalistic stimuli on the model's filters and performance, as well as on LPLC2 neuron responses themselves. 

For simplicity, this model did not impose the hexagonal geometry of the compound eye ommatidia. Instead, we assume that the visual field is separated into a Cartesian lattice with $5^{\circ}$ spacing, each representing a local motion detector with two spatially separated inputs (Fig. \ref{fig:stimuli_flow}). This simplification alters slightly the geometry of the motion signals compared to the real motion detector receptive fields \citep{shinomiya2019comparisons}. This could potentially affect the learned spatial weightings and reproduction of the LPLC2 responses to various stimuli, since the specific shapes of the filters matter (Fig. \ref{fig:replication}). Thus, the hexagonal ommatidial structure and the full extent of inputs to T4 and T5 might be crucial if one wants to make comparisons with the dynamics and detailed responses of LPLC2 neurons. However, this geometric distinction seems unlikely to affect the main results of how to infer the presence of looming stimuli.

Our model requires a field of estimates of the local motion. Here, we used the simplest model -- the Hassenstein-Reichardt correlator model \ref{eq:HRC} \citep{hassenstein1956systemtheoretische} -- but the model could be extended by replacing it with a more sophisticated model for motion estimation. Some biophysically realistic ones might take into account synaptic conductances \citep{gruntman2018simple,gruntman2019computation,badwan2019dynamic,zavatone2020minimal}. Alternatively, in natural environments, contrasts fluctuate in time and space. Thus, if one includes more naturalistic spatial and temporal patterns, one might consider a motion detection model that can adapt to changing contrasts in time and space  \citep{drews2020dynamic,matulis2020heterogeneous}. The tuning curve of any motion estimator depends on the spatial offsets of the inputs and the timescales of the temporal filters. A relevant quantity for looming stimuli is the $R/v$ ratio, where $R$ is the radius of the object and  $v$ is the velocity at which the object is moving. The ratio determines a timescale for the expansion of a looming object on a collision course, in which a short timescale corresponds to a fast-moving object. In our simulations, we kept the ratio in a range that makes the HRC output roughly proportional to the velocity (Eq. \ref{eq:HRC}) [WILL ADD A FIGURE].

Our neural network model is highly constrained by the specific anatomy of LPLC2 circuits, and no unnecessary layers were added. The resulting model is a shallow neural network (Fig. \ref{fig:anatomy} and Fig. \ref{fig:model}). This shallowness leads to limited dimensionality of the model, which will be prone to finding non-optimal local minima during training. Indeed, in many cases, the training resulted in models with poor performance and filters with weights very close to zero. We minimized this problem by choosing the initialization scales for the filters so that optimization resulted in meaningful models with structured filters about half of the time. However, the ratio of the outward and inward solutions shown in Fig. \ref{fig:outward_prevail}B was not affected by the initialization scales. [Maybe add supp figure to show this?]

Although the outward filter of the unit emerges naturally from our gradient descent training protocol, that does not mean that the structure is learned by LPLC2 neurons in the fly. There is some experience dependent plasticity in the fly eye \citep{kikuchi2012experience}, but these visual computations are likely to be primarily genetically determined. Thus, one could think of the computation of the LPLC2 neuron as being shaped through millions of years of evolution. Interestingly, optimization algorithms similar to evolution may be able avoid getting stuck in local optima \citep{stanley2019designing}, and thus work well with the sort of shallow neural network found in the fly eye.

In this study, we focused on the motion signal inputs to LPLC2 neurons, and we neglected other inputs to LPLC2 neurons, such as inputs coming from the lobula that likely report non-motion visual features. It would be interesting to investigate how this additional non-motion information would affect the performance and optimal solutions of the inference units. For instance, another lobula columnar neurons, LC4, is loom sensitive and receives inputs in the lobula \citep{von2017feature}. The LPLC2 and LC4 neurons are the primary excitatory inputs to the GF, which mediates the escape behavior of a fly \citep{von2014spike, ache2019neural}. The inference framework set out here would allow one to incorporate of parallel non-motion intensity channels, either by adding them into the inputs to the LPLC2-like units, or by adding in a parallel population of LC4-like units. This would require a reformulation of the probabilistic model in Eq. (\ref{eq:prob_model}). Notably, one of the most studied loom detecting neurons, the lobula giant movement detector (LGMD) in locusts, does not appear to receive direction-selective inputs, as LPLC2 does \citep{rind1996neural,gabbiani1999computation}. Thus, the inference framework set out here can be flexibly modified to investigate loom detection under a wide variety of constraints and inputs, which allow it to be applied to other neurons, beyond LPLC2. 

\newpage

\section{Methods and Materials}

\subsection{Code availability}
Code to perform all simulations in this paper and to reproduce all figures is available at \\ http://www.github.com/ClarkLabCode/XXXXX.

\subsection{Coordinate system and stimuli}
We designed a suite of visual stimuli to present to our models to simulate looming objects that hit or miss the fly, retreating objects, and rotational visual fields. In this section, we describe the suite of stimuli and the coordinate systems used in our simulations.

In our simulations and training, the fly sits on a horizontal plane, and its head points towards a specific direction. The fly head is modeled to be a point particle with no volume. A three dimensional right-handed frame of reference $\Sigma$ is set up and attached to the fly head (origin): the $z$ axis points in the anterior direction from the fly head, perpendicular to the line that connects the two eyes, and in the horizontal plane of the fly; the $y$ axis points toward the right eye, also in the horizontal plane; and the $x$ axis points upward and perpendicular to the horizontal plane. Looming or retreating objects are represented in this space by a sphere with radius $R=1$, and the coordinates of its center at time $t$ are denoted as $\mathbf{r}(t) = (x(t),y(t),z(t))$. Thus, the distance between the object center and the fly head is $D(t) = |\mathbf{r}(t)| = \sqrt{x^{2}(t)+y^{2}(t)+z^{2}(t)}$.

Within this coordinate system, we set up cones to represent individual units. The receptive field of LPLC2 neurons is measured at roughly 60-degree in diameter \citep{klapoetke2017ultra}. Thus, we here model each unit as a cone with its vertex at the origin and with half-angle of 30 degrees. The orientation of the axis of the cone can be characterized by two of the Euler angles $\psi$ (around $z$) and $\theta$ (around the new $x^{'}$ axis after the rotation around $z$) with respect to the frame of reference. For each unit $m$ ($m=1, 2, \dots, M$), we set up a local frame of reference $\Sigma_{m}$ (Fig. (\ref{figsupp:sf1})): the $z_{m}$ axis is the axis of the cone and its positive direction points outward from the origin, the $x_{m}$ axis lies in the plane spanned by the $x$ axis of $\Sigma$ and the $z_{m}$ axis of $\Sigma_{m}$ and has an acute angle with the positive direction of $x$ axis of $\Sigma$, and the $y_{m}$ axis should be chosen such that $\Sigma_{m}$ is right-handed. For each unit, its cardinal directions are defined as: upward (positive direction of $x_{m}$), downward (negative direction of $x_{m}$), leftward (negative direction of $y_{m}$ and rightward (positive direction of $y_{m}$. To get the signals that are received by a specific unit $m$, the coordinates of the object in $\Sigma$ are rotated to the local frame of reference $\Sigma_{m}$.

Within this coordinate system, we can also set up cones representing the extent of a spherical object moving in the space. The visible outline of a spherical object spans a cone with its point at the origin. The half-angle of this cone is a function of time and can be denoted as $\theta_{\text{s}}(t)$:
\begin{equation}
\theta_{\text{s}}(t) = \arcsin{\frac{R}{D(t)}}.
\end{equation}
One may calculate how the cone of the object overlaps with the receptive field cones of each unit.

There are multiple layers in the fly visual system \citep{takemura2017comprehensive}, but here we focus on only two coarse grained stages of processing: (1) the estimation of local motion direction from optical intensities by motion detection neurons T4 and T5 and (2) the integration of the flow fields by LPLC2 neurons. In our simulations, the interior of the $m$th unit cone is represented by a $N$ by $N$ matrix, so that each element in this matrix indicates a specific direction in the angular space within the unit cone. If an element also falls within the object cone, then its value is set to 1; otherwise it is 0. Thus, at each time $t$, this matrix is an optical contrast signal and can be represented by $C(x_{m},y_{m},t)$, where $(x_{m},y_{m})$ are the coordinates in $\Sigma_{m}$. In general, $N$ should be big enough to provide good angular resolutions. Then, $K^{2}$ ($K<N$) motion detectors are evenly distributed within the LPLC2 cone, with each occupying a $L$ by $L$ grid in the $N$ by $N$ matrix, where $L=N/K$. This $L$ by $L$ grid represents a $5^{\circ}$ by $5^{\circ}$ square in the angular space, consistent with sizes of the receptive fields of motion detectors T4/T5 \citep{zavatone2020minimal}. Since the receptive field of an LPLC2 neuron is roughly $60^{\circ}$, the value of $K$ is set to be 12. To get enough angular resolution for the local motion detectors, the value of $L$ is set to be 4, and this makes the value of $N$ to be 48.

Each motion detector is assumed to be a Hassenstein Reichardt Correlator (HRC) and calculates local flow fields from $C(x_{m},y_{m},t)$ \citep{hassenstein1956systemtheoretische}. The HRC used here has two inputs, separated by $5^{\circ}$ in the angular space. Each input applies first a spacial filter on the contrast $C(x_{m},y_{m},t)$ and then temporal filters:
\begin{align}
I_{j}(t;x_{m},y_{m}) = \sum_{t^{'}=0}^{t}\sum_{x^{'}_{m}=-N}^{N}\sum_{y^{'}_{m}=-N}^{N}f_{j}(t^{'})G(x^{'}_{m},y^{'}_{m})C(x_{m}-x^{'}_{m},y_{m}-y^{'}_{m},t-t^{'}),
\end{align}
where $f_{j}\ (j \in {1,2})$ is a temporal filter and $G$ is a discrete 2d Gaussian kernel with mean $0^{\circ}$ and standard deviation of $2.5^{\circ}$ to account for the acceptance angle of the fly photoreceptors \citep{stavenga2003angular}. For simplicity, the temporal filters $f_{1}$ and $f_{2}$ were chosen to be two delta functions: $f_{1}(t^{'})=\delta (t^{'}-(t-\Delta))$ and $f_{2}=\delta (t^{'}-t)$, with one peaking with a delay at $t-\Delta$ and the other at the current time $t$, where $\Delta$ was set to 0.03 s \citep{salazar2016direct}. With these, we have:
\begin{align}\label{eq:HRC}
F(t;x_{m1},y_{m1},x_{m2},y_{m2}) = I_{1}(t;x_{m1},y_{m1})I_{2}(t;x_{m2},y_{m2})-I_{1}(t;x_{m2},y_{m2})I_{2}(t;x_{m1},y_{m1}).
\end{align}
where $F(t;x_{m1},y_{m1},x_{m2},y_{m2})$ is the local flow fields at time $t$ with two inputs locating at $(x_{m1},y_{m1})$ and $(x_{m2},y_{m2})$, respectively.

In experiment, four types of T5 neurons have been found that project to layers 1, 2, 3, and 4 of the lobula plate. Each type is sensitive to one of the cardinal directions: down, up, left, right \citep{maisak2013directional}. Thus, in our model, there are four nonnegative, local flow fields that serve as the only inputs to the model: $U_{-}(t)$ (downward, corresponding LP layer 4), $U_{+}(t)$ (upward, LP layber 3), $V_{-}(t)$ (leftward, LP layer 1) and $V_{+}(t)$ (rightward, LP layer 2), each of which is a $K$ by $K$ matrix. To calculate these matrices by Eq. \ref{eq:HRC}, two sets of motion detectors are needed, one for the vertical directions and one for the horizontal directions. The HRC model in Eq. \ref{eq:HRC} is direction sensitive and has opponency, which means that for motion in the preferred (null) direction, the output of the HRC model is positive (negative) \citep{adelson1985spatiotemporal}. Thus, assuming the upward (rightward) is the preferred vertical (horizontal) direction, we can get the elements of the four flow fields, respectively:
\begin{align*}
[U_{-}(t)]_{k_{1}k_{2}} &= \lvert \min(0,F(t;x_{m1},y_{m},x_{m2},y_{m})) \rvert \nonumber \\
[U_{+}(t)]_{k_{1}k_{2}} &= \lvert \max(0,F(t;x_{m1},y_{m},x_{m2},y_{m})) \rvert \nonumber \\
[V_{-}(t)]_{k_{1}k_{2}} &= \lvert \min(0,F(t;x_{m},y_{m1},x_{m},y_{m2})) \rvert  \nonumber \\
[V_{+}(t)]_{k_{1}k_{2}} &= \lvert \max(0,F(t;x_{m},y_{m1},x_{m},y_{m2})) \rvert,
\end{align*}
where $k_{1},k_{2} \in \{1,2,\dots,K\}$ and $\lvert \cdot \rvert$ represents the absolute value. In the above expressions, it implies, for $[U_{-}(t)]_{k_{1}k_{2}}$ and $[U_{+}(t)]_{k_{1}k_{2}}$, the vertical motion detector at $(k_{1},k_{2})$ has its two inputs located at $(x_{m1},y_{m})$ and $(x_{m2},y_{m})$, respectively. Similarly, for for $[V_{-}(t)]_{k_{1}k_{2}}$ and $[V_{+}(t)]_{k_{1}k_{2}}$, the horizontal motion detector at $(k_{1},k_{2})$ has its two inputs located at $(x_{m},y_{m1})$ and $(x_{m},y_{m2})$.

We simulated the trajectories $\mathbf{r}(t)$ of the object in the frame of reference $\Sigma$ with a time resolution of 0.01 s. For hit, miss, and retreat cases, the trajectories of the object are always straight lines (i.e., ballistic motion), and the velocities of the object were randomly sampled from a range $[2R,10R](s^{-1})$ and all the trajectories are confined to be within a sphere of $5R$ (All figures except Fig. \ref{figsupp:sf1_outward_prevail}C) or $10R$ (Fig. \ref{figsupp:sf1_outward_prevail}C) (\textcolor{red}{Supplementary figures are not referenced correctly.}) centered at the fly head. The radius of the object, $R$, was always set to be 1. To generate rotational stimuli, we placed 100 objects at random positions around the fly, and rotated them all about a specific axis certain axis. The rotation speed was chosen from a Gaussian distribution with a mean $0^{\circ}/s$ and standard deviation $200^{\circ}/s$, a reasonable rotational velocity for walking flies \citep{deangelis2019manifold}.


\subsection{Models}
Experiments have shown that an LPLC2 neuron has four dendritic structures in the four LP layers, and that they receive direct excitatory inputs from T4/T5 motion detection neurons \citep{maisak2013directional,klapoetke2017ultra}. Besides, it has been proposed that each dendritic structure also receive inhibitory inputs mediated by lobulate plate intrinsic interneurons, such as LPi4-3 \citep{klapoetke2017ultra}. Thus, our models have two types of nonnegative filters, one excitatory and one inhibitory (Fig. \ref{fig:model}), represented by $W^{\text{e}}$ and $W^{\text{i}}$, respectively. Each filter is a $12$ by $12$ matrix. Next, we rotate counterclock wise $W^{\text{e}}$ and $W^{\text{i}}$ by multiples of $90^{\circ}$ to obtain the filters that are used to integrate the four motion signals: $U_{-}(t)$, $U_{+}(t)$, $V_{-}(t)$, $V_{+}(t)$. Specifically, we define the corresponding four excitatory filters as: $W^{\text{e}}_{U_{-}}=\text{rotate}(W^{\text{e}},270^{\circ})$, $W^{\text{e}}_{U_{+}}=\text{rotate}(W^{\text{e}},90^{\circ})$, $W^{\text{e}}_{V_{-}}=\text{rotate}(W^{\text{e}},180^{\circ})$, $W^{\text{e}}_{V_{+}}=\text{rotate}(W^{\text{e}},0^{\circ})$, and the inhibitory filters as: $W^{\text{i}}_{U_{-}}=\text{rotate}(W^{\text{i}},270^{\circ})$, $W^{\text{i}}_{U_{+}}=\text{rotate}(W^{\text{i}},90^{\circ})$, $W^{\text{i}}_{V_{-}}=\text{rotate}(W^{\text{i}},180^{\circ})$, $W^{\text{i}}_{V_{+}}=\text{rotate}(W^{\text{i}},0^{\circ})$. In addition, we impose mirror symmetry to the filters, and with the above defitions of the rotated filters, the upper half of $W^{\text{e}}$ is a mirror image of the lower half of $W^{\text{e}}$. The same mirror symmetry also applies to $W^{\text{i}}$. Thus, there are in total 144 parameters in the two sets of filters. In fact, since only the elements within a 60 degree cone contribute to the filter for the units, the corners are neglected, and there are only 112 trainable parameters in the excitatory and inhibitory filters.

In computer simulations, the weights and flow fields are flattened to be one-dimensional column vectors. The responses of the inhibitory units are:
\begin{align*}
r^{\text{i}}_{U_{-}}(t) &= \phi \left[ (W^{\text{i}}_{U_{-}})^{T}U_{-}(t)+b^{\text{i}} \right] \nonumber \\
r^{\text{i}}_{U_{+}}(t) &= \phi \left[ (W^{\text{i}}_{U_{+}})^{T}U_{+}(t)+b^{\text{i}} \right] \nonumber \\
r^{\text{i}}_{V_{+}}(t) &= \phi \left[ (W^{\text{i}}_{V_{+}})^{T}V_{+}(t)+b^{\text{i}} \right] \nonumber \\
r^{\text{i}}_{V_{-}}(t) &= \phi \left[ (W^{\text{i}}_{V_{-}})^{T}V_{-}(t)+b^{\text{i}} \right],
\end{align*}
where $\phi(\cdot) = \max(\cdot,0)$ is the rectified linear activation function, and $b^{\text{i}} \in \mathbb{R}$ is the intercept.

The response of a single unit $m$ is:
\begin{multline}\label{eq:LPLC2_response}
r_{m}(t) = \phi \Bigg[ (W^{\text{e}}_{U_{-}})^{T}U_{-}(t)+(W^{\text{e}}_{U_{+}})^{T}U_{+}(t)+(W^{\text{e}}_{V_{+}})^{T}V_{+}(t)+(W^{\text{e}}_{V_{-}})^{T}V_{-}(t)- \\
\left(r^{\text{i}}_{U_{-}}(t)+r^{\text{i}}_{U_{+}}(t)+r^{\text{i}}_{V_{+}}(t)+r^{\text{i}}_{V_{-}}(t)\right)+b^{\text{e}} \Bigg],
\end{multline}
where $b^{\text{e}} \in \mathbb{R}$ is the intercept (\ref{fig:model}).

The inferred probability of hit for a specific trajectory is:
\begin{equation}
\hat{P}_{\text{hit}} =\frac{1}{T}\sum_{t=1}^{T} \sigma \left( \sum_{m}r_{m}(t)+b \right),
\label{eq:prob_model}
\end{equation}
where $T$ is the total time steps of the trajectory and $\sigma(\cdot)$ is the sigmoid function. Since we are adding three intercepts $b^{\text{i}}$,$b^{\text{e}}$, and $b$, there are 115 parameters to train in this model.

There are some variations of the above model that have also been tested. The first variation introduces a modified probability model compared with Eq. \ref{eq:prob_model}:
\begin{equation}
\hat{P}^{'}_{\text{hit}} = \frac{1}{T}\sum_{t=1}^{T}\left[ 2\sigma \left( \sum_{m}r_{m}(t) \right)-1 \right].
\label{eq:prob_model2}
\end{equation}

A second variation we tested is a modification of Eq. (\ref{eq:LPLC2_response}), where the inhibitory units are deleted and the filters, represented by $W^{\text{'}}_{U_{-}},W^{\text{'}}_{U_{+}},W^{\text{'}}_{V_{+}},W^{\text{'}}_{V_{-}}$, are allowed to have both positive and negative values, i.e.,
\begin{equation}
r_{m}^{'}(t) = \phi \left[ (W^{\text{'}}_{U_{-}})^{T}U_{-}(t)+(W^{\text{'}}_{U_{+}})^{T}U_{+}(t)+(W^{\text{'}}_{V_{+}})^{T}V_{+}(t)+(W^{\text{'}}_{V_{-}})^{T}V_{-}(t)+b^{'} \right].
\label{eq:LPLC2_response_2}
\end{equation}

\subsection{Training and testing}
We created a synthetic data set containing four types of motions: \emph{loom-and-hit}, \emph{loom-and-miss}, \emph{retreat}, and \emph{rotation}. The proportions of these types were 0.25, 0.125, 0.125, 0.5 respectively. In total, there were 5200 trajectories, with 4,000 for training and 1,200 for testing. Trajectories with motion type \emph{loom-and-hit} are labeled as hit or $y_{n}=1$ (probability of hit is 1), while trajectories of other motion types are labeled as non-hit or $y_{n}=0$ (probability of hit is 0), where $n$ is the index of each specific sample.

The loss function to be minimized in our training was the cross entropy between the label $y_{n}$ and the inferred probability of hit $\hat{P}_{\text{hit}}$, and averaged across all samples, plus a regularization term:
\begin{equation}
\text{loss}=-\frac{1}{N}\sum_{n=1}^{N}\left[ y_{n}\log \hat{P}_{\text{hit}}(n)+(1-y_{n})\log (1-\hat{P}_{\text{hit}}(n) \right]+\beta\sum_{W}\Vert W \Vert^{2},
\end{equation}
where $\hat{P}_{\text{hit}}(n)$ is the inferred probability of hit for sample $n$, $\beta$ is the strength of an L2 regularization, and $W$ represents all the effective parameters in the two excitatory and inhibitory filters.

The strength of the regularization $\beta$ was set to be $10^{-4}$, which was obtained by gradually increasing $\beta$ until the performance of the model on test data started to drop. The regularization sped up convergence of solutions, but the regularization strength did not strongly influence the main results in the paper, as long as it was not too strong, that is, as long as it was much less than 1.

To speed up training, rather than taking a temporal average as shown in Eq. (\ref{eq:prob_model}), a snapshot was sampled randomly from each trajectory, and the probability of hit of this snapshot was used to represent the whole trajectory, i.e., $\hat{P}_{\text{hit}}=\sigma \left( \sum_{m}r_{m}(t)+b \right)$, where $t$ is a random sample from $\{1,2,\dots,T\}$. Mini-batch gradient descent was used in training, and the learning rate was 0.001.

After training, the models were tested on the entire trajectories with the probability of hit defined in Eq. (\ref{eq:prob_model}). Models trained only on snapshots data performed very well on the test data. During testing, the performance of the model was evaluated by the area under the curve (AUC) of the receiver operating characteristic (ROC) and precision-recall (PR) curves \citep{hanley1982meaning,davis2006relationship}.



TensorFlow \citep{abadi2016tensorflow} was used to train all models.

\subsection{Clustering the solutions}
To cluster the solutions, we used the following procedure. Each solution had an excitatory and an inhibitory filter. We flattened these two filters, and concatenated them into a single vector. (The elements at the corners were deleted since they are outside of the receptive field.) Thus, each solution was represented by a vector, from which we calculated the cosine distance for each pair of solutions. The obtained distance matrix was then fed into a hierarchical clustering algorithm \citep{2020SciPy-NMeth}. After obtaining the hierarchical clustering, the outward and inward filters were identified by their shape. We summed the element values of filter corresponding to flow with components radiating outwards and subtracted the values of the filter corresponding to flow with components directed inwards. If this sum was positive, then the filters were labeled as outward; otherwise, the filters were labeled as inward. If the elements in the concatenated vector are all close to zero, then the corresponding filters were labeled as unstructured.

\subsection{Statistics}
For a model with $M$ units, where $M \in \{1,2,4,8,16,32,64,128,192,256\}$, 200 random initializations were used to train it. Within these 200 trainings, the numbers of outward solutions $N_{\text{out}}$ are (starting from smaller M's): 33, 44, 42, 46, 50, 49, 51, 50, 49, 46 (out of 150), and the numbers of inward solutions $N_{\text{in}}$ are: 70, 67, 68, 67, 66, 64, 60, 33, 27, 12 (out of 150). The average score curves and dots in Fig. \ref{fig:outward_prevail}A) were obtained by taking average among each type of solutions, respectively, and the shades indicate one standard deviation. The curve and dots in Fig. \ref{fig:outward_prevail}B) are the ratio of the number of outward solutions to the number of inward solutions. To obtain the error bar (grey shade), we considered the training results as a binomial distribution, with the probability to get the outward solutions being $N_{\text{out}}/(N_{\text{out}}+N_{\text{in}})$, and the inward being $N_{\text{in}}/(N_{\text{out}}+N_{\text{in}})$. Thus, the standard deviation of this binomial distribution is $\sigma_{\text{b}}=\sqrt{N_{\text{out}}N_{\text{in}}/(N_{\text{out}}+N_{\text{in}})}$, which should be on both $N_{\text{out}}$ and $N_{\text{in}}$. From this, we can calculate the error bar as the propagated error \citep{caldwell2015propagation}:
\begin{equation}
\text{propagated error} = \frac{N_{\text{out}}}{N_{\text{in}}}\sqrt{\left(\frac{\sigma_{\text{b}}}{N_{\text{out}}}\right)^{2}+\left(\frac{\sigma_{\text{b}}}{N_{\text{in}}}\right)^{2}}.
\end{equation}




\section{Acknowledgments}

We thank ...

\bibliography{references}





\end{document}
